# RIL-Contour: a Medical Imaging Dataset Annotation Tool for and with Deep Learning

Kenneth A. Philbrick et. al. Mayo Clinic etc.

## 0. Abstract

Deep-learning algorithms typically fall within the domain of supervised artificial intelligence and are designed to "learn" from annotated data. Deep-learning models require large, diverse training datasets for optimal model convergence. The effort to curate these datasets is widely regarded as a barrier to the development of deep-learning systems. We developed RIL-Contour to accelerate medical image annotation for and with deep-learning. A major goal driving the development of the software was to create an environment which enables clinically oriented users to utilize deep-learning models to rapidly annotate medical imaging. RIL-Contour supports using fully automated deep-learning methods, semi-automated methods, and manual methods to annotate medical imaging with voxel and/or text annotations. To reduce annotation error, RIL-Contour promotes the standardization of image annotations across a dataset. RIL-Contour accelerates medical imaging annotation through the process of annotation by iterative deep learning (AID). The underlying concept of AID is to iteratively annotate, train, and utilize deep-learning models during the process of dataset annotation and model development. To enable this, RIL-Contour supports workflows in which multiple-image analysts annotate medical images, radiologists approve the annotations, and data scientists utilize these annotations to train deep-learning models. To automate the feedback loop between data scientists and image analysts, RIL-Contour provides mechanisms to enable data scientists to push deep newly trained deep-learning models to other users of the software. RIL-Contour and the AID methodology accelerate dataset annotation and model development by facilitating rapid collaboration between analysts, radiologists, and engineers.

深度学习算法大多都是监督学习的形式，设计为从标注数据进行学习。深度学习模型需要大型、多样的训练数据集，以进行最优的模型收敛。维护这些数据的工作，一般认为是深度学习系统开发的障碍。我们开发了RIL-Contour系统，以加速医学图像标注，采用了深度学习技术，同时也为深度学习技术服务。驱动软件开发的一个主要目标，是创建一个环境，使临床目标的用户利用深度学习模型来迅速标注医学图像。RIL-Contour支持使用全自动的深度学习方法，半自动的方法，和手工的方法，来标注医学影像，以体素标注的形式，或文本标注的形式。为降低标注误差，RIL-Contour推动在一个数据集中使用标准化的图像标注。RIL-Contour通过迭代深度学习(AID, annotation by iterative deep learning)方法的标注的过程，加速了医学图像标注。AID的潜在概念是，迭代的标注、训练，并在数据集标注和模型开发的过程中利用深度学习模型。为实现这些功能，RIL-Contour支持的工作流包括，多个图像分析师标注医学图像，放射科医生批准标注，数据科学家利用这些标注来训练深度学习模型。为使数据科学家和图像分析师的这个反馈循环自动化，RIL-Contour提供的机制，可以使数据科学家将新训练的深度学习模型到其他使用这个软件的用户那里。RIL-Contour和AID方法，通过促进分析师，放射科医生和工程师的合作，加速了数据集标注和模型开发。

**Keywords** Deep-learning . Medical image annotation . Annotation by iterative deep learing (AID) . Segmentation . Classification . Software tools

## 1. Introduction

Deep-learning algorithms typically fall within the domain of supervised artificial intelligence and are designed to "learn" from annotated data [1]. Deep-learning models require large, diverse training datasets for optimal model convergence. The ImageNet dataset used to train powerful general-purpose deep-learning image classifiers contains millions of unique images each annotated to describe the objects contained within the image [2]. While usually smaller, datasets used to train powerful medical image classifiers typically contain hundreds-to-thousands of annotated images [3–7]. The effort required to curate these training datasets is widely regarded as a major barrier to the development of deep-learning systems.

深度学习算法一般都是监督学习的类型，可以从标注的数据中进行学习。深度学习需要大型的，多样化的训练数据集，以得到最优的模型收敛。用于训练通用目标的深度学习图像分类器的ImageNet数据集，包含数百万幅图像，每一幅都进行了标注，描述每幅图像中所包含的目标。用于训练医学图像分离器的数据集通常更小一些，包含数百到数千幅标注图像。维护这些训练数据集的工作，一般都认为是开发深度学习系统的主要障碍。

Numerous software tools have been developed to annotate medical imaging [8–18]. These tools commonly provide manual, semi-automated, and fully automated methods to label imaging. Semi-automated methods typically utilize traditional image processing techniques such as thresholding or edge detection [9, 10, 12, 19]. Fully automated methods are typically built upon semi-automated techniques and human-designed algorithms which encode domain-specific knowledge [13, 15, 17, 19]. Development of these algorithms is time consuming and the computational time associated with running many of them can be substantial.

开发了很多工具软件来标注医学影像。这些工具一般提供了手动，半自动，和全自动的方法来标注图像。半自动的方法，一般是利用传统的图像处理技术，比如阈值，或边缘检测。全自动的方法，一般是在半自动的方法和人类设计的算法上构建起来的，包含了领域特定的知识。这些算法的开发是很耗时的，很多算法的运行时间会非常好。

Deep-learning algorithms "learn" to identify objects of interest in imaging data [1]. Utilizing deep-learning–based approaches for medical imaging annotation does not require the development of traditional human engineered algorithms. In many cases, deep-learning approaches to image analysis have been found to meet or exceed the performance of traditional algorithms [20, 21]. The computational time required to perform inference utilizing deep-learning models is often lower than traditional approaches. This suggests that implementing a deep-learning–based approach for dataset annotation may meet or exceed the performance of traditional human-designed annotation algorithms.

深度学习算法在图像数据中学习怎样去识别目标。利用基于深度学习的方法进行医学影像标注，不需要开发传统的人类设计的算法。在很多情况中，深度学习方法对图像分析的性能已经达到或超过了传统算法。利用深度学习模型进行推理所需的计算时间通常比传统方法要少。这说明，实现一个基于深度学习模型的方法，进行数据集标注，可能会达到或超过传统的人类设计的标注算法的性能。

Medical image annotation software often does not provide tools that standardize the annotations used across datasets. Many annotation tools create annotations on an ad hoc basis. These tools place the burden of maintaining consistency in annotation labels on the analyst and have inspired efforts to standardize annotation lexicon [22]. Errors or variability in data annotation increases the size of the dataset required for deep-learning model convergence to a "correct" generalizable solution [23]. Errors specifically in the definition of the test dataset make it difficult to determine "true" model performance as model divergence from the test dataset may be appropriate.

医学图像标注软件通常没有对整个数据集的标注进行标准化的工具。很多标注工具都是以临时的方式创建标注。这些工具将维护标注标签一致性的责任放在了分析师身上，启发了将标注字典标准化的工作。深度学习模型要收敛到一个正确的可泛化的解，在数据标注时的错误或变化，会使对数据集规模的要求变大。在测试数据集中的定义的错误，会使确定模型的真实性能变得困难，因为模型与测试数据集的偏差可能会是合适的。

Once created, annotation metadata must be associated in some fashion with the original imaging. Errors here result in annotation data loss and/or dataset corruption. The Digital Imaging and Communications in Medicine (DICOM) standard provides one solution to these challenges by enabling annotation metadata to be non-destructively embedded directly within medical imaging. This, however, alters the imaging files and can complicate using the same imaging for multiple annotation projects. Alternatively, if annotation data are not embedded within imaging then annotation metadata must be saved and associated in some fashion with the original imaging. Content management systems have historically provided a partial solution to these data management challenges. These systems provide database-like mechanisms to store and manage imaging and its associated metadata [24, 25]. However, annotation tools are usually stand-alone and not well integrated with content management systems. This lack of integration complicates workflows by requiring the image analyst to manage the movement of data between the content management system and the annotation software. The addition of these workflow steps results in the inability to guarantee that annotation metadata is correctly captured by a content management system.

一旦创建以后，标注的元数据需要以某种方式与原始图像进行关联。这里的错误会导致标注数据的损失和/或数据集的损坏。DICOM标准为这些挑战提供了一个解决方案，使标注的元数据直接嵌入到医学影像中，而不损坏原始图像。但是，这改变了图像文件，在使用同样的图像进行多个标注项目时，会变得复杂。或者，如果标注数据没有嵌入到影像中，那么标注的元数据必须保存下来，并与原始图像以某种方式进行关联。内容管理系统过去对这种数据管理的挑战提供了一种部分解决方案。这些系统提供了类似数据库的机制，以存储并管理影像及其相关的元数据。但是，标注工具通常是独立的，与内容管理系统并没有进行很好的集成。这种集成的缺位，会使得工作流程变得复杂，需要图像分析师来管理数据在内容管理系统和标注软件中的移动。这些流程步骤的加入，会使得，内容管理系统对标注元数据的正确捕获，无法得到保证。

## 2. Software Overview

We developed Radiology Informatics Laboratory Contour (RIL-Contour) to accelerate medical image annotation for and with deep learning. A major goal driving the development of the software was to create an environment which enables clinically oriented users to focus on annotating imaging datasets using deep-learning methods and not on the underlying challenges associated with data transformation or management. Unlike annotation tools designed to annotate single images, RIL-Contour facilitates the consistent annotation of large medical imaging datasets required for developing deep- learning models and promotes collaborative dataset annotation by supporting concurrent multiuser workflows.

我们开发了RIL-Contour，以加速医学图像标注。开发这个软件的主要目标，是创建一个环境，使得临床目标的用户可以聚焦在使用深度学习方法标注图像数据集，而不需要关注与数据变换或管理相关的挑战上。与设计用于标注单幅图像的标注工具不同，RIL-Contour促进了大型医学影像数据集的一致标注，然后用于深度学习模型的开发，通过支持并发多用户流程，促进了数据集合作标注。

RIL-Contour defines voxel and imaging annotation definitions at the "dataset level" to enforce consistency of annotation definitions across all images in a dataset. This is similar to the concept of annotation template definitions used in other software [11]. RIL-Contour supports the use of deep-learning models to automatically perform voxel and text annotation of imaging. Additionally, RIL-Contour provides mechanisms to perform advanced deep-learning model visualization to aid image analysts and data scientists in understanding deep-learning models and provides methods to automate quantification of Dice and Jaccard metrics for deep-learning segmentation models.

RIL-Contour在数据集层次定义了体素和图像标注的定义，以对一个数据集中所有图像的标注定义的一致性作出强制。这与其他软件中的标注模版定义的概念类似。RIL-Contour支持使用深度学习模型来自动进行图像的体素和文本标注。此外，RIL-Contour提出了一些机制，以进行高级的深度学习模型可视化，来辅助图像分析师和数据科学家理解深度学习模型，并提供为深度学习分割模型进行自动计算Dice和Jaccard度量的方法。

RIL-Contour stores annotation metadata independently from imaging to enable imaging to be used in multiple annotation projects and to guarantee that the act of annotation does not alter image data files. RIL-Contour manages the storage of annotation metadata. While not common, other annotation tools provide similar functionality [11]. For datasets stored on a file system, RIL-Contour automatically maintains the file association between annotation metadata and imaging. Alternatively, RIL-Contour can be linked with a Medical Imaging Research Management and Associated Information Database (MIRMAID) content management system [24]. In this later configuration, RIL-Contour will silently retrieve imaging on demand and push and pull annotation metadata to and from the content management system.

RIL-Contour将标注元数据与影像文件进行独立存储，以可以在多个标注工程中使用，并确保标注的行为并没有改变图像文件本身。RIL-Contour管理标注元数据的存储。虽然并不常见，其他标注工具也提供的类似的功能。对于在文件系统中存储的数据集，RIL-Contour自动维护标注元数据与影像的文件关联。或者，RIL-Contour可以与医学影像研究管理和关联信息数据(MIRMAID)内容管理系统相连。在这后者的配置中，RIL-Contour会静默按需检索影像，从内容管理系统中拉取并向之推送标注元数据。

## 3. RIL-Contour User Interface

Upon loading, RIL-Contour presents two windows, the dataset project viewer (Fig. 1(a)) and the dataset annotation window (Fig. 1(b)). The dataset project viewer displays a list of the imaging files associated with a project. The project viewer is designed to simplify the complexity of working with large datasets. From the user’s perspective, the dataset project viewer displays files in a hierarchy which mirror the datasets storage on the file system or for a content-managed dataset in a DICOM-inspired Patient → Study → Series hierarchy. The menus shown on the dataset project viewer window broadly provide access to dialogs which control project-wide settings (e.g., annotation definitions) and dialogs that perform operations across the project’s dataset (e.g., exporting data). Series which have been edited are bolded, allowing the user to quickly identify annotated imaging, and textual annotations associated with imaging can be shown as optional columns.

在软件打开时，RIL-Contour会有两个窗口，数据集工程浏览器（图1a）和数据集标注窗口（图1b）。数据集工程浏览器展现的是与一个工程相关的影像文件列表。工程浏览器的设计是简化对大型数据集标注的复杂度。从用户的角度，数据集工程浏览器以层次化的方式展示文件，将数据集在文件系统中的存储，或内容管理数据集上的存储，映射到显示上，层次关系为DICOM启发的患者-Study-Series。在数据集工程浏览器窗口上显示的菜单栏，大致可以给出一些对话框，控制工程中的设置（如，标注定义），和在工程的数据集中进行的操作的对话框（如，导出数据）。已经编辑过的Series是加粗的，使用户迅速识别标注的影像，与影像相关的文本标注，可以展示为可选的列。

The dataset annotation window is the primary interface through which annotation is performed (Fig. 1(b)). RIL-Contour supports voxel annotations to define regions of interest (ROI) within images and text annotations to describe location-independent features or observations (e.g., image quality, presence of features, comments). RIL-Contour supports associating voxel ROI annotations with RadLex identification numbers (RadLex ID) to enable ROI definitions to be associated with a universally identifiable numerical nomenclature [22]. All dataset annotation operations are saved automatically as they are performed. For file system–based projects, the software supports versioning image annotations and supports common related versioning operations (e.g., viewing a version change history and rolling back to a previous version). To enable multiple users to utilize the same source imaging for independent annotation projects, RIL-Contour supports saving annotation data in an independent location on the file system or within a MIRMAID content management system [24].

数据集标注窗口，是进行标注的主要界面（图1b）。RIL-Contour支持体素标注来定义图像中的ROI，和文本标注，以描述与位置相关的特征或观察（如，图像质量，特征是否存在，评论）。RIL-Contour支持将体素ROI标注与RadLex识别码关联起来，以将ROI的定义与唯一可识别数值命名关联起来。所有数据集标注操作都在进行的时候自动保存。对于基于文件系统的工程，软件支持图像标注的版本控制，支持一般的版本操作（如，查看版本变化历史，回滚到前一个版本）。为使多个用户利用同样的图像源，以进行独立的标注工程，RIL-Contour支持将标注数据保存到一个独立的位置，可以在文件系统中，也可以在一个MIRMAID内容管理系统。

## 4. Voxel Annotations

RIL-Contour supports "area" and "point" voxel annotations to define ROIs within images (Fig. 2). Area annotations describe multi-voxel patches that can be used to either train an algorithm for segmentation or for classification. These annotations are often defined on multiple slices, and thus can represent multi-slice volumes. Point annotations describe the location of point(s) of interest within a series and can be used to define anatomical locations within a series or specifying the presence or absence of feature(s) within a slice. Descriptive statistics for a selected annotation can be shown through the statistics window (Fig. 3).

RIL-Contour支持区域和点的体素标注，来定义图像中的ROIs（图2）。区域标注描述了多体素块，可以用于训练一个分割算法，或分类算法。这些标注通常定义在多个slices上，因此可以表示多slice的体。点标注描述一个series中感兴趣点的位置，可以用于定义一个series中解剖位置，或指定一个slice中特征的存在与否。对于一个选定的标注的描述性的统计，可以用于在统计窗口中展示（图3）。

Manual definition of ROI is performed using the voxel annotation tools and filters. These tools and filters support common drawing operations (e.g., painting, erasing, filling, dilation, erosion, and undo/redo). RIL-Contour supports labeling voxels with multiple annotation labels, e.g., a voxel could be annotated as both kidney and tumor. Alternatively, the software can be set to enforce a one ROI per voxel mapping; e.g., a voxel could be annotated as a kidney or tumor but not both (Fig. 2). All manual segmentation tools support threshold-based application to selectively perform the desired annotation operation on voxels within a defined value range. The paint brush and eraser tools support cross-slice painting to automatically extend the operation to a predetermined number of adjacent slices. The histogram shown on the statistics window (Fig. 3) can be useful in determining the threshold range exhibited by a partially annotated tissue. The combination of threshold-based painting and multi-slice painting facilitates rapid manual segmentation of tissues which exhibit values which strongly differentiate them from surrounding structures. Finally, all ROI annotations support locking to prevent the ROI from being modified using manual, semi-automated, and fully automated deep-learning techniques.

ROI的手工定义是通过使用体素标注工具和过滤器来进行的。这些工具和过滤器支持常用的画图操作（如，画图，擦除，填充，膨胀，腐蚀，以及撤销/重做）。RIL-Contour支持用多个标注标签标注体素，如，一个体素可以同时标注为肾脏和肿瘤。或者，软件可以设置为，每个像素智能映射到一个ROI；如，一个体素可以标注为肾脏或肿瘤，但不能标注为两者（图2）。所有的手工标注工具都支持基于阈值的应用，以在体素上在定义的值范围内选择性的进行期望的标注操作。画刷和擦除工具支持跨slice的画画，以自动的将这个操作拓展到一个预定义的相邻slice数量。在统计窗口上展示的灰度直方图（图3），在确定部分标注的组织上的阈值范围上是有用的。基于阈值的绘图和多slice绘图的结合，可以促进一些组织的快速分割，这些组织的值与周围的值差异很大。最终，所有ROI标注都支持锁定，以防止ROI被手动、半自动和自动深度学习方法所改变。

RIL-Contour supports semi-automated ROI generation and edge refinement using the Minimal Interaction Rapid Organ Segmentation (MIROS) algorithm [26]. This algorithm was developed to refine the boundary of high-contrast organs (Fig. 4). Semi-automated edge refinement can be performed for a single slice using the "Snap Contour" and for multiple slices using the "Auto-Contouring" or "Batch Contouring" user interfaces (Fig. 1(b)). Slice segmentations generated wholly using semi-automated methods are illustrated within the slice viewer by a lighter version of the ROI’s color to differentiate them from user-edited annotations (Fig. 1(b)).

RIL-Contour支持半自动的ROI生成，和边缘提炼，使用的是Minimal Interaction Rapid Organ Segmentation (MIROS)算法。这种算法是用于提炼高对比度器官的边缘（图4）。半自动的边缘提炼可以对单个slice使用，使用的是Snap Contour，也可以使用界面中的"Auto-Contouring" 或 "Batch Contouring"对多个slices使用（图1b）。用半自动方法提取出的Slice分割，在slice浏览器中展示，使用的ROI的颜色的更浅的版本，以区分用户编辑的标注（图1b）。

## 5. Text Annotations

RIL-Contour supports descriptive text annotations to capture non-voxel-based observations. Text annotations can be restricted to a predefined set of values to standardize annotations. All text annotations can be shown as optional columns in the dataset project viewer to identify images in the dataset containing the text annotation.

RIL-Contour支持描述性的文本标注，以捕获基于非体素的观察结果。文本标注可以限制在预定义的值的集合，以对标注进行标准化。所有的文本标注可以在数据集工程浏览器中显示为可选列，以识别数据集中的图像包含文本标注。

## 6. Import and Exporting Annotations

RIL-Contour supports importing and exporting ROI voxel annotation data to and from binary file masks. To define multiple overlapping ROI in a single binary voxel mask, files can be written out as the "binary or" of the overlapping ROI mask values. For masks exported to the file system, annotation masks are written in a hierarchy that mirrors the original dataset. Masks exported to the file system are accompanied by a data file describing the binary mask, e.g., mapping between the ROI mask value and a RadLex ID. Copies of the original input imaging and original RIL-Contour annotation data file can optionally also be written out. For content-managed workflows, binary masks can be exported back into a MIRMAID content management system or to the file system. Alternatively, descriptive statistics of voxel annotations and tables listing the text annotations associated with imaging can be exported in Excel (Microsoft, Redmond, WA) or comma-separated value (CSV) format.

RIL-Contour支持ROI体素标注数据的导入和导出，格式为二值mask文件。为在单个二值体素mask中定义多个重叠的ROI，文件可以写成重叠的ROI mask值的二值or。对于导出到文件系统的masks，标注的masks写成一种层次结构，与原始数据集的结构形成镜像。导出到文件系统的masks，伴有一个数据文件，描述的是二值mask，如，在ROI mask值与RadLex ID之间的映射。原始输入影像的副本，和原始的RIL-Contour标注数据文件，也有选项可以被写出。对于内容管理工作流程，二值masks可以导出到MIRMAID内容管理系统中，或到文件系统中。另外，体素标注的描述性的统计，和文本标注的表格列表，可以导出为Excel，或CSV文件。

## 7. Concurrent User Annotation and Multiuser Workflows

RIL-Contour supports concurrent dataset annotation by multiple users. For datasets stored in a MIRMAID content management system, RIL-Contour utilizes locking mechanisms to enable multiple users to concurrently annotate independent imaging series. For datasets stored on the file system, RIL-Contour supports series locking and additionally supports multiuser workflows which define series-specific user-level rights to generate annotations for imaging and define the set of other software users to which a user can assign image annotation rights to. These workflows are designed to enable multiple people to work concurrently to annotate, review, and utilize the data for machine-learning purposes. Figure 5 illustrates an example annotation workflow in which multiple-image analysts generate annotations, the generated annotations are reviewed, and the resulting annotations are used by data scientists to train a deep-learning model. To support these workflows, RIL-Contour automatically versions series annotations when series ownership changes. RIL-Contour multiuser workflows are described in a YAML file which can be optionally embedded within a RIL-Contour project description file or specified at run time through a command line option.

RIL-Contour支持多个用户的并发数据集标注。对于存储在MIRMAID内容存储系统的数据集，RIL-Contour利用锁定机制以使多个用户同时标注独立的影像series。对于存储在文件系统中的数据集，RIL-Contour支持series锁定和额外的多用户工作流，定义了series专用的用户级权利，来生成影像标注，并定义其他软件用户的集合，一个用户可以指定图像标注权给这些用户。这些工作流设计用于多人同时工作，以对数据进行标注，回顾并用于机器学习目的。图5描述了一个标注流程的例子，其中多个图像分析师生成标注，生成的标注进行审核，得到的标注被数据科学家使用，以训练一个深度学习模型。为支持这些工作流程，在series所有者改变时，RIL-Contour自动对series标注进行版本控制。RIL-Contour多用户工作流程在一个YAML文件中描述，这个文件是可以在一个RIL-Contour工程描述文件中的，或在运行时通过一个命令行选项进行指定。

## 8. Deep-Learning Powered Annotation

RIL-Contour supports utilizing trained deep-learning models to perform fully automated annotation. RIL-Contour utilizes a "no-coding" plugin architecture to make it relatively simple to deploy deep-learning models in the software. The plugin interface is designed to run deep-learning models developed in Keras running on Tensorflow. The plugin execution framework instantiates models on demand. The time required to load a model is related to the model complexity. Once loaded, the computational costs associated with model inference for most models are typically low enough that models can be run on a standard modern CPU.

RIL-Contour支持利用训练好的深度学习模型，以进行全自动的标注。RIL-Contour利用一个no-coding插件架构，使其相对容易的将深度学习模型部署到软件中。这个插件的界面设计用于运行深度学习模型，是TensorFlow Keras训练得到的。插件的运行框架按照需求对模型进行实例化。加载一个模型所需的时间，与模型复杂度相关。一旦加载后，与模型推理相关的计算代价，一般都非常低，可以在标准的现代CPU上进行运行。

RIL-Contour defines the preprocessing operations (e.g., normalization, mapping model output to annotation settings) required for model inference in metadata which it stores alongside an HDF5 file that describes the model’s weights and optionally architecture. To enable model metadata to be defined with little-to-no coding, RIL-Contour provides a model creation wizard that resides inside of a model manager dialog that steps users through the definition of the requisite metadata (Fig. 6).

RIL-Contour在元数据中定义了模型推理所需的预处理操作（如，归一化，将模型输出映射到标注的设置），存储在一个HDF5文件中，包含了模型的权重，也可以包含模型架构。为使模型的元数据用很少或没有代码进行定义，RIL-Contour提供了一个模型创建向导，在一个模型管理器对话框中，用户可以根据这些步骤，通过需要的元数据的定义进行操作（图6）。

The RIL-Contour model manager supports model versioning and model sharing. Model versioning is designed to enable models to be easily updated with a new set of learned weights and/or architecture while maintaining a history of prior model configurations. The software supports importing and exporting models with their definition metadata and has functions to automate model discovery to enable models to be automatically imported into the software as they are made available. This feature has been designed to enable data scientists to "push" new and updated deep-learning models to other users of the software (Fig. 5).

RIL-Contour模型管理器支持模型版本控制和模型共享。模型版本控制的设计是使模型可以很容易的更新，同时维护之前的模型配置的历史。软件支持用元数据定义导入和导出模型，有自动模型发现的功能，以使得模型一旦可用，就自动导入到软件中。这个特征设计用于数据科学家将新的和更新的深度学习模型推送到软件的其他用户（图5）。

## 9. Understanding Model Inference

RIL-Contour supports the interactive generation of visualizations which identify the regions of images that models identify when performing prediction (Fig. 7) [4]. The software supports a variety of state-of-the-art visualization approaches such as saliency maps, class activation maps (CAM), gradient class activation maps (Grad-CAM), and saliency activation maps (SAM) [4, 27–30]. These techniques allow analysts without a data science background to quickly and intuitively understand the regions of an image that a deep-learning model responds to. Each of the model visualization techniques employed within RIL-Contour generates an "activation" metrics for each voxel. To enable users to rapidly focus on meaningful regions of activation, RIL-Contour performs automatic thresholding to hide low-intensity background activations; this setting can also be dynamically adjusted by the analyst.

RIL-Contour支持可视化的互动生成，识别预测时模型识别的图像区域（图7）。软件支持很多目前最好的可视化方法，比如显著性图，类别激活图，梯度类别激活图，和显著性激活图。这些技术使没有数据科学背景的分析师，可以迅速的直觉的理解一幅图像中深度学习模型响应的区域。RIL-Contour中采用的每个模型的可视化技术，对每个体素生成一个激活矩阵。为使用户迅速聚焦在激活的有意义区域，RIL-Contour进行了自动阈值，以隐藏那些低灰度的背景激活；这些设置可以由分析师动态的调整。

## 10. Deep-Learning Model Segmentation Model Metrics

RIL-Contour supports automated quantification of Dice and Jacard segmentation metrics between a deep-learning model’s predictions and image segmentations defined in the software. Metrics are computed on a per-slice basis for slices selected in the software. Slice segmentations metrics are summarized as volume segmentation metrics.

RIL-Contour支持Dice和Jaccard分割指标的自动定量计算，在一个深度学习模型的预测和软件中定义的图像分割结果中计算。这些度量是在软件中选择slice，然后逐slice计算的。Slice分割度量总结成了体分割度量。

## 11. Annotation by Iterative Deep Learning

The time required to curate large datasets is a major roadblock to developing novel deep-learning models. RIL-Contour can accelerate data annotation through the process of annotation by iterative deep learning (AID). AID accelerates dataset annotation by utilizing deep-learning models to generate draft annotations. AID is based on the observation that it is typically faster for humans to edit or correct a good- but-not-perfect image annotation than to generate one entirely from scratch.

维护大型数据集所需的时间，是开发新的深度学习模型的主要障碍。RIL-Contour可以通过AID加速数据标注。AID通过利用深度学习模型来生成标注草稿，加速数据集标注。AID是基于下面的观察，即人们修改或编辑一个还不错，但并不完美的图像标注，比完全从头标注，要更快一些。

Using the AID process, dataset annotation begins with an entirely unannotated dataset. From this, a small subset of the data is selected and annotated using traditional methods. This initial annotated dataset is then used to train a "development" deep-learning model to perform the desired annotation. This "development" model is then deployed from within RIL-Contour to generate draft annotations for the next set of training data. The newly created draft annotations are then corrected as necessary from within the RIL-Contour and the now expanded annotated dataset is exported from the software and used to train the next "development" model. This process is repeated iteratively until the entire dataset is annotated or until a model is created with sufficient accuracy that further iteration is no longer required. The AID methodology is illustrated in Figs. 5 and 8. Conceptually, AID is described as a cycle. However, given sufficient human resources, model development and dataset annotation can be conducted concurrently (Fig. 5); new models can be developed as new data becomes available and deep-learning annotation models can be utilized as they are created.

使用AID过程，数据集标注开始的时候，是完全未标注的数据集。从这开始，先选择一个数据的小的子集，使用传统方法进行标注。这个初始的标注数据集，用于训练一个开发的深度学习模型，以进行想要的标注。这个开发的模型，然后部署到RIL-Contour中，以对下一个训练集的数据生成标注草稿。新创建的标注草稿然后在RIL-Contour中按照需求进行修改，现在扩展的标注的数据集从软件中导出，用于训练下一个开发模型。这个过程进行迭代的重复，直到整个数据集进行了标注，或直到一个模型达到足够的准确率，不需要更多的标注了。AID方法如图5和如8所示。概念上来说，AID是一个循环。但是，只要有足够的人力资源，模型开发和数据集标注可以同时进行（图5）；新的模型可以开发，新的数据变得可用，只要深度学习标注模型训练出来，就可以进行利用。

We have utilized RIL-Contour for multiple annotation projects. These projects have used the software for annotation of MRI, CT, and US imaging collected at the head, chest, and abdomen to generate annotations of brain, abdominal organs, tumors, and other tissues and to generate annotations that categorically classify the presence or absence of tumors in imaging or the contrast enhancement phase of a CT series. To date, we have used RIL-Contour to perform data annotation for over 12 projects. We report several case studies to illustrate how RIL-Contour can be used to accelerate medical image annotation.

我们在多个标注工程中利用了RIL-Contour。这些工程使用了软件来标注MRI，CT和US图像，包括头，胸，腹的部位，生成了脑、腹部器官、肿瘤，和其他组织的标注，生成的标注可以将影像或对比度增强的CT进行归类，是否存在肿瘤。迄今为止，我们使用RIL-Contour标注了12个工程。我们给出了几个案例研究，描述了RIL-Contour怎样用于加速医学图像标注。

Our largest project to date involves segmenting 35 unique organs and tissues in CT volumes of the abdomen. Project staff consists of 17 image analysts, 5 radiologists, and 3 data scientists who coordinate solely through RIL-Contour. Qualitatively, AID methodology greatly decreased the human time required to annotate new series for this project. Initially, starting from minimal base annotations, annotators required approximately 40 h to fully segment the abdominal organs in a series. At present, we have 99 annotated volumes annotated. The AID methodology has decreased average volume annotation time to approximal 8 h per series, 80% reduction in annotation time.

迄今为止我们最大的工程，包括分割CT中腹部的35个器官和组织。工程员工包括17个图像分析员，5个放射科医生，和3个数据科学家，都采用了RIL-Contour来协调。定量的来说，AID的方法极大的降低了人标注新序列的时间。最初，从最小基准标注开始，标注者需要大约40h来完全分割一个series的腹部器官。目前，我们有99个标注好的体。AID方法降低了平均体的标注时间，达到了每个series 8h，减少了80%的标注时间。

In another example, we created a novel dataset to train a deep-learning model to locate the vertebral bodies. Seven analysts utilized the software to define the desired anatomy. The entire project, which involved segmentation of 132 cases, took less than a week from conception to successful conclusion.

在另一个例子中，我们创建了一个新的数据集，以训练一个新的深度学习模型，来定位椎体。7个分析师利用软件定义期望的解剖结构。整个工程，包含132例分割，只用了不到一个星期，从概念到完全结束。

In another example, we utilized RIL-Contour to categorically annotate the contrast enhancement phase of abdominal CT imaging. Annotations were generated by 3 radiologists. Three thousand images were annotated. These annotations were used to train a contrast enhancement prediction model [4]. A RIL-Contour plugin for this model is shared on GitLab (see "Software Availability").

在另一个例子中，我们利用RIL-Contour来分类标注对比度增强腹部CT影像。标注是由3个放射科医生完成的。标注了3000幅图像。这些标注用于训练一个对比度增强预测模型。在Gitlab上分享了一个RIL-Contour插件。

We have found RIL-Contour to be a useful tool for deploying deep-learning models to collaborators who may have little-to-no experience with machine learning. In a recent example, we utilized RIL-Contour to correlate body composition, in particular visceral adiposity, with waist-hip measurements taken at our clinic. RIL-Contour’s no-coding interface allowed our collaborator, who had no experience coding, to utilize deep-learning models to perform automated segmentation after an hour of training.

我们发现RIL-Contour是一个非常有用的工具，可以部署深度学习模型，而用户则几乎没有机器学习经验。在一个最近的例子中，我们利用了RIL-Contour来将身体组成部分进行相关，特别是内脏肥胖，还包含了在我们诊所进行的腰臀测量。RIL-Contour的无代码界面，使得没有任何编程经验的合作者，可以利用深度学习模型在几个小时训练后进行自动分割。

## 12. Discussion

The development of deep-learning models for medical imaging typically requires the annotation of hundreds-to-thousands of images [3–7]. This process is time consuming and potentially error prone. Software tools which facilitate rapid accurate image annotation and annotation review are needed to accelerate the development of deep-learning datasets and models.

对医学图像的深度学习模型的开发，一般数百到数千幅图像的标注。这个过程很消耗时间，很可能出错。需要促进快速准确的图像标注和标注审查的软件工具，以加速深度学习数据集和模型的开发。

RIL-Contour has been designed with the goals of accelerating the annotation of medical imaging for deep learning. RIL-Contour contour accomplishes this by (1) providing a tool that simplifies the challenges of working with large imagining datasets in a collaborative research environment, (2) by providing a tool that enables deep-learning models to be utilized directly from within the software to perform fully automated annotation, and (3) by providing a tool that facilitates the visualization of and understanding of deep-learning models.

RIL-Contour的设计目标是加速医学图像标注。RIL-Contour通过一下方法完成这个目标，(1)提供了一个工具，使得在协同研究环境中用大型图像数据集进行工作变得更简单，(2)提供了一个工具，可以使用深度学习模型，进行全自动的标注，(3)提供了一个工具，促进深度学习模型的可视化和理解。

Variability or errors in dataset annotation increase the size of the training dataset required for accurate deep-learning model convergence [23]. A strategy utilized by other medical imaging software has been to standardize definition of annotations across the images in a dataset using templates [11]. RIL-Contour adopts a similar strategy to ensure consistency in the definition of annotations in a dataset. This design paradigm guarantees that a given ROI will have the same name, RadLex ID, and voxel mask value for all images in a RIL-Contour dataset and that text annotations will fall within a predefined set of values.

数据集标注中的变化或错误，使得训练准确的深度学习模型收敛，所需的训练数据集变大。其他医学成像软件所利用的一个策略是，利用模板，对整个数据集的标注的定义进行标准化。RIL-Contour采用了类似的策略，以确保数据集中的标注定义的一致性。这种设计范式，确保了在一个RIL-Contour数据集中的所有图像中，一个给定的ROI会有相同的名称，RadLex ID，和体素mask值，文本标注的值会有预定义的集合。

Few medical imaging research annotation tools are designed to manage the association between imaging and annotation metadata when the metadata is not stored directly within the source imaging. A notable expectation is the work of Rubin et al. [11]. Content management systems such as MIRMAID and Extensible Neuroimaging Archive Toolkit (XNAT) provide systems to accomplish this [24, 25]. However, in working with most annotation software, these systems typically require the data analyst to manually move data between annotation software and the content management system. These additional steps add workflow complexity and are potentially error prone. RIL-Contour provides a mechanism to manage the association between imaging data and annotation metadata for datasets stored on the file system or within a MIRMAID content management system. These interfaces are designed to minimize workflow complexity and empower the data analyst to focus on data annotation and review and not on the management of imaging and metadata.

在元数据没有直接存储在源影像中时，很少有医学影像研究标注设计用于管理影像和标注元数据的关系。一个值得注意的工作是Rubin et al. [11]。内容管理系统，比如MIRMAID和XNAT，可以完成这个功能。但是，在与多数标注软件一起工作时，这些系统一般需要数据分析师手动将数据在标注软件和内容管理系统中移动。这些额外的步骤增加了工作流程的复杂度，可能会出现错误。RIL-Contour提供了一个机制，对存储在文件系统或在MIRMAID内容管理系统中的文件，管理影像数据和标注元数据的关系。这些界面设计将工作流复杂度最小化，对数据分析师进行赋能，使其关注在数据标注和复核中，而不用关注影像和元数据的管理。

RIL-Contour is designed to simplify the application of deep-learning models for the purposes of medical image annotation. RIL-Contour utilizes a plugin engine to load and run deep-learning models at run time. The RIL-Contour engine supports models developed in Keras running on Tensorflow. Future support for additional platforms is planned. To execute a model, the plugin engine loads the model at run time, from source or an HDF5 file, normalizes and transforms the input imaging to match the model’s requirements, runs the model, and, for segmentations, transforms the model output into RIL-Contour voxel annotations. The plugin engine enables RIL-Contour to interact directly with models. This allows RIL-Contour to provide a graphical user interface (GUI) model definition wizard which walks users through the process of importing a deep-learning model based, in part, on the underlying architecture of the model and enables the software to provide model visualization features which rely on the ability to rewrite a model and compute the output and gradient of arbitrary model layers.

RIL-Contour设计用于简化深度学习模型在医学影像标注中的应用。RIL-Contour利用一个插件引擎在运行时运行深度学习模型。RIL-Contour引擎支持在TensorFlow Keras上开发的模型。未来计划会支持更多的平台。为执行一个模型，插件引擎在运行时加载模型，从源文件或HDF5文件，将输入影像进行变换和归一化，以匹配模型的要求，运行这个模型，对分割来说，将模型输出转化到RIL-Contour体素标注中。插件引擎使RIL-Contour与模型直接互动。这使RIL-Contour可以有一个GUI模型定义向导，使用户走过下面的过程，即输入一个深度学习模型，使软件提供模型的可视化特征，等。

To our knowledge, DeepInfer is the only other medical image annotation tool developed to facilitate automated image annotation using deep learning [31]. DeepInfer is a 3D Slicer plugin which enables 3D Slicer to utilize deep-learning models to perform fully automated image annotation [9, 31]. In terms of functionality, RIL-Contour and DeepInfer both automate the application of deep-learning models for the purposes of data annotation. DeepInfer utilizes a Docker-based execution engine to run deep-learning models. Due to its Docker-based design, DeepInfer does not directly interact with models and as a result cannot directly perform the model modifications required for the generation of advanced visualizations.

据我们所知，用深度学习来促进自动图像标注的医学图像标注，只有DeepInfer。DeepInfer是一个3D Slicer插件，使3D Slicer可以利用深度学习模型来进行全自动的图像标注。以功能来说，RIL-Contour和DeepInfer都使得深度学习模型可以对数据标注产生自动化的效果。DeepInfer利用一个基于Docker的执行引擎，来运行深度学习模型。由于其基于Docker的设计，DeepInfer并没有直接与模型互动，结果是，不能直接进行模型修改，而这是高级可视化生成所必须的。

The RIL-Contour plugin interface currently supports two-dimensional models and patch-wise application of three-dimensional models for segmentation or classification. Support for whole volume three-dimensional models is planned. The generation of CAM visualizations requires CAM-specific model architecture, within network SAM and Grad-CAM layer visualizations are supported for both convolutional and activation layers with non-linear activation functions [4, 27, 28, 30].

RIL-Contour插件界面目前支持二维模型和三维模型的逐块应用，用于分割或分类。计划支持整个体的三维模型。CAM可视化的生成，需要特征的CAM模型架构，在网络中SAM和Grad-CAM的层可视化是支持的。

The effort required to curate training datasets for deep learning is widely regarded as a major barrier to the development of deep-learning models. Numerous groups have attempted to accelerate machine-learning model training through processes designed to optimize the creation of training datasets [32–34]. Deep-learning methods have been proposed to accelerate interactive segmentation and to propagate segmentations across slices [35]. Other techniques, auto-annotation and pseudo-annotation, utilize multiple instance learning to automatically identify meaningful annotations from a set of predetermined noisy labels; labels that both correctly and incorrectly label data [36–38].

为深度学习维护训练数据集的努力，是深度学习模型开发的一个主要障碍。很多小组尝试，通过设计用于优化训练数据集的创建的过程，加速深度学习模型的训练。深度学习方法的提出是用于加速互动分割和在不同的slices中传播分割。其他技术，自动标注和伪标注，利用多个实例学习来从预定义的含噪的标签中自动识别有意义的标注；包括正确和不正确的标注数据的标签。

Here, we propose the AID methodology to accelerate human-driven data annotation of medical imaging. AID is an example of how artificial intelligence can be used to augment and accelerate human performance while retaining human supervision. AID methodology is similar to a classification-based annotation system described for natural world images [32]. The underlying premise behind AID is that a machine-learning model can be used during the construction of a supervised training dataset and that the amount of human correction required following application of a model will be approximately proportional with the overall size and diversity of the model's training dataset. RIL-Contour is designed to facilitate AID by (1) enabling deep-learning models to be applied to annotation images from within the software, (2) by providing mechanism from within the software to edit deep-learning derived annotations, (3) by providing a mechanism to export data to promote rapid model training, (4) by supporting concurrent workflows, and (5) by providing mechanisms which automate the sharing of deep-learning models between users of the software.

这里，我们提出AID方法来加速医学影像数据标注。AID是人工智能怎样用于扩充和加速人类行为，同时保持人类监督的例子。AID方法与一种用于自然图像的基于分类的标注系统类似。AID背后潜在的前提是，机器学习模型可以用于构建一个监督训练集，在使用深度学习后，人们需要进行的修改，与模型训练集的规模和多样性是近似成比例的。RIL-Contour的设计可以促进AID，通过(1)深度学习模型可以应用于在软件中标注图像，(2)提供一种机制，在软件中可以修改，(3)提供了一种机制，将数据导出，以促进模型快速训练，(4)支持并发工作流，(5)提供了一种机制，将深度学习模型在软件用户之间的共享自动化。

A limitation of RIL-Contour is the software has been designed to facilitate annotation of imaging stored in the Neuroimaging Informatics Technology Initiative (NIfTI) file format [39]. There are numerous tools (e.g., dcm2niix, MRIConvert) which can be used to convert DICOM imaging to the NIfTI file format. The NIfTI file format is a simpler format than the DICOM file format [39]. The NIfTI file format has been designed to encapsulate multi-dimensional imaging data within a single file. At present, there is a well-developed Python API to reliably read and write the file format, there are a number of medical imaging tools which read and write the format, and the format is extensively utilized within medical imaging research community [8–10, 12–14, 17, 24, 39]. A major limitation of the NIfTI file format is that it fails to capture much of the metadata commonly stored within DICOM files. To overcome this limitation, RIL-Contour supports the association of additional imaging metadata as a secondary CSV file and supports reading and writing this additional metadata from a MIRMAID content management system [24]. A focus of future development efforts is to add support in RIL-Contour to natively support datasets stored in DICOM.

RIL-Contour的一个局限是，软件设计用于促进的图像标注，只支持NIfTI格式。有很多工具可以用于将DICOM影像转换成NIfTI文件格式。NIfTI文件格式比DICOM文件格式要更简单。NIfTI文件格式设计用于包装多维影像数据到一个文件中。目前，有一个开发的很好的Python API，可以可靠的读写这种文件格式，有很多医学影像工具对这个格式进行读写，这个格式在很多医学影像研究团体得到了应用。NIfTI文件格式的一个主要局限是，不能捕获DICOM文件中的很多元数据。为克服这种限制，RIL-Contour支持关联额外的影像元数据，以CSV文件格式，支持从MIRMAID内容管理系统中读写这种多于的元数据。未来的开发努力的一个焦点是，在RIL-Contour中支持DICOM格式的数据集。

RIL-Contour exports annotated voxel data as NIfTI files aligned to match the orientation and alignment of the source imaging. Additional non-imaging metadata is exported as tabular data in CSV and Excel format. These representations are programmatically convenient to work with. However, they do not facilitate broad data interoperability. The DICOM file format is capable of describing both imaging and metadata (contours, points, binary masks, and non-imaging data). The DICOM format is fully capable of encapsulating the metadata generated using RIL-Contour. A focus of future development efforts is to add support in RIL-Contour to export annotated datasets in the DICOM format to facilitate the utilization of RIL-Contour annotated datasets in other software packages.

RIL-Contour导出标注的体素数据为NIfTI文件，与原影像的方向和对齐方式进行匹配。另外的非影像元数据导出为表格数据，格式为CSV和Excel。这些表示可以很容易进行编程。但是，没有促进广泛的数据互操作性。DICOM文件格式可以描述影像数据和元数据（轮廓，点，二值掩膜，和非影像数据）。DICOM格式完全能够封装RIL-Contour生成的元数据。未来开发的一个焦点，是在RIL-Contour中支持DICOM格式的数据集标注，促进RIL-Contour用于标注其他软件包中的数据集。

## 13. Conclusion

Deep-learning models are widely believed to require large training datasets for generalizable model convergence. The time required to annotate such datasets is a major barrier to the development of these models. We have developed the software RIL-Contour to accelerate medical imaging dataset annotation for deep learning. RIL-Contour provides annotation mechanisms designed to standardize annotation definitions and provides tools to easily apply deep-learning models to perform fully automated text and voxel annotation. RIL-Contour supports collaborative workflows and has been designed to accelerate annotation through the process of AID—a process through which deep-learning models are iteratively trained and utilized to generate draft annotation for a dataset that can then be edited as necessary.

深度学习模型一般需要大型训练数据集来得到可泛化的模型收敛。标注这种数据集的时间，是开发这种模型的主要障碍。我们已经开发了RIL-Contour软件，来加速医学影像数据集的标注。RIL-Contour提供的标注机制，可以使用标准化的标注定义，提供的工具可以很容易的应用深度学习模型来进行完全自动的文本和体素标注。RIL-Contour支持协同的工作流，设计用于通过AID来加速标注过程，这个过程通过迭代训练的深度学习模型，用其生成勾画草稿，然后进行修改和编辑。