# Holistically-Nested Edge Detection

Saining Xie, Zhuowen Tu, University of California, San Diego

## 0. Abstract

We develop a new edge detection algorithm that addresses two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning. Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets. HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to resolve the challenging ambiguity in edge and object boundary detection. We significantly advance the state-of-the-art on the BSD500 dataset (ODS F-score of .782) and the NYU Depth dataset (ODS F-score of .746), and do so with an improved speed (0.4s per image) that is orders of magnitude faster than some recent CNN-based edge detection algorithms.

我们提出了一种新的边缘检测算法，处理这个存在已久的视觉问题中的两个重要问题：(1)整体性的图像训练与预测，(2)多尺度多级别特征学习。我们提出的方法，整体嵌套边缘检测(HED)，使用深度学习模型进行图像到图像的预测，模型利用的是全卷积神经网络和深度监督网络。HED自动学习丰富的层次化表示（由在副响应上的深度监督进行引导），对于解决边缘和目标边界检测中的模糊性问题非常重要。我们在BSD500和NYU深度数据集上显著推动了目前最好的水平（ODS F-score分别为0.782和0.746），处理的速度更快（每幅图像0.4s），比一些最近的基于CNN的边缘检测算法快了几个数量级。

## 1. Introduction

In this paper, we address the problem of detecting edges and object boundaries in natural images. This problem is both fundamental and of great importance to a variety of computer vision areas ranging from traditional tasks such as visual saliency, segmentation, object detection/recognition, tracking and motion analysis, medical imaging, structure-from-motion and 3D reconstruction, to modern applications like autonomous driving, mobile computing, and image-to-text analysis. It has been long understood that precisely localizing edges in natural images involves visual perception of various “levels” [18, 27]. A relatively comprehensive data collection and cognitive study [28] shows that while different subjects do have somewhat different preferences regarding where to place the edges and boundaries, there was nonetheless impressive consistency between subjects, e.g. reaching F-score 0.80 in the consistency study [28].

本文中，我们处理在自然图像中检测和边缘和目标轮廓的问题。这个问题是很基本的，对很多计算机视觉领域问题都很重要，从传统的任务，如视觉显著性，分割，目标检测/识别，跟踪，和运动分析，医学成像，从运动恢复结构，和3D重建，到现代的应用，如自动驾驶，移动计算，和图像到文本的分析。在自然图像中精确的定位边缘，长久以来一直的理解是，很多不同层次的视觉感知。一个相对综合的数据收集和认知研究[28]表明，不同的对象对哪里是边缘和边界有不同的看法，尽管如此，不同对象还是有一致性的，如，在一致性研究中达到0.80的F-score[28]。

The history of computational edge detection is extremely rich; we now highlight a few representative works that have proven to be of great practical importance. Broadly speaking, one may categorize works into a few groups such as I: early pioneering methods like the Sobel detector [20], zero-crossing [27, 37], and the widely adopted Canny detector [4]; methods driven by II: information theory on top of features arrived at through careful manual design, such as Statistical Edges [22], Pb [28], and gPb [1]; and III: learning-based methods that remain reliant on features of human design, such as BEL [5], Multi-scale [30], Sketch Tokens [24], and Structured Edges [6]. In addition, there has been a recent wave of development using Convolutional Neural Networks that emphasize the importance of automatic hierarchical feature learning, including N4-Fields [10], Deep-Contour [34], DeepEdge [2], and CSCNN [19]. Prior to this explosive development in deep learning, the Structured Edges method (typically abbreviated SE) [6] emerged as one of the most celebrated systems for edge detection, thanks to its state-of-the-art performance on the BSD500 dataset [28] (with, e.g., F-score of .746) and its practically significant speed of 2.5 frames per second. Recent CNN-based methods [10, 34, 2, 19] have demonstrated promising F-score performance improvements over SE. However, there still remains large room for improvement in these CNN-based methods, in both F-score performance and in speed — at present, time to make a prediction ranges from several seconds [10] to a few hours [2] (even when using modern GPUs).

计算边缘检测的历史非常丰富；我们现在强调一些代表性工作，这些都已被证明具有很大的实践重要性。广泛的说，可以将这些工作分成几类，如I：早期的先驱性方法，如Sobel检测器[20]，zero-crossing[27,37]，以及广泛采用的Canny检测器[4]；由II驱动的方法：经过仔细手动设计得到的特征之上的信息论方法，如统计边缘[22]，Pb[28]，和gPb[1]；和III：基于学习的方法，依靠人工设计的特征，如BEL [5], Multi-scale [30], Sketch Tokens [24], 和Structured Edges [6]。另外，最近有很多基于CNN的工作，强调自动层次化特征学习的重要性，包括N4-Fields [10], Deep-Contour [34], DeepEdge [2], 和CSCNN [19]。在深度学习的爆发性发展之前，Structured Edges方法（简化为SE）[6]成为一种最著名的边缘检测方法，在BSD500数据集上有目前最好的性能（F-score为0.746），速度也非常快，达到了2.5fps。最近的基于CNN的方法[10,34,2,19]已经证明了在SE的基础上都不错的F-score改进。但是，在这些基于CNN的方法中仍然存在很大的改进空间，包括F-score的改进和速度的改进，目前，进行一次预测的时间在几秒到几小时之间（即使使用了现代GPU也是）。

Here, we develop an end-to-end edge detection system, holistically-nested edge detection (HED), that automatically learns the type of rich hierarchical features that are crucial if we are to approach the human ability to resolve ambiguity in natural image edge and object boundary detection. We use the term “holistic”, because HED, despite not explicitly modeling structured output, aims to train and predict edges in an image-to-image fashion. With “nested”, we emphasize the inherited and progressively refined edge maps produced as side outputs — we intend to show that the path along which each prediction is made is common to each of these edge maps, with successive edge maps being more concise. This integrated learning of hierarchical features is in distinction to previous multi-scale approaches [40, 41, 30] in which scale-space edge fields are neither automatically learned nor hierarchically connected. Figure 1 gives an illustration of an example image together with the human subject ground truth annotation, as well as results by the proposed HED edge detector (including the side responses of the individual layers), and results by the Canny edge detector [4] with different scale parameters. Not only are Canny edges at different scales not directly connected, they also exhibit spatial shift and inconsistency.

这里，我们提出一种端到端的边缘检测系统，整体嵌套边缘检测(HED)，自动学习丰富的关键的层次化特征的类型，如果我们要接近人类解决自然图像中边缘和边界检测的模糊性的能力，这是很重要的。我们使用“整体”的术语是因为，HED没有显式的对结构化的输出进行建模，其目标是以一种图像到图像的方式，训练和预测图像。使用“嵌套”，我们强调的是，其内在的和渐进的提炼的边缘图，生成为副输出，我们想要展示的是，进行每个预测，所走的道路，对于每个边缘图来说，都是很常见的，而随后的边缘图会更加简洁。这种层次化特征的集成学习与之前的多尺度方法非常不同，那些方法中，尺度空间边缘场既不是自动学习的，也不是层次化的连接到一起的。图1给出了一个例子，有人类主观的真值标注，以及HED边缘检测器的结果（包含个体层中的副响应），以及不同尺度参数下的Canny边缘检测结果。不仅不同尺度下的Canny边缘不是直接连接到一起的，而且还表现出了空间的偏移和不一致性。

The proposed holistically-nested edge detector (HED) tackles two critical issues: (1) holistic image training and prediction, inspired by fully convolutional neural networks [26], for image-to-image classification (the system takes an image as input, and directly produces the edge map image as output); and (2) nested multi-scale feature learning, inspired by deeply-supervised nets [23], that performs deep layer supervision to “guide” early classification results. We find that the favorable characteristics of these underlying techniques manifest in HED being both accurate and computationally efficient.

提出的整体嵌套边缘检测(HED)处理两个关键的问题：(1)对于图像到图像的分类（系统以图像为输入，直接生成边缘图作为输出）的整体图像训练和预测，这是由全卷积网络[26]启发得到的；(2)嵌套多尺度特征学习，受深度监督网络[23]启发，进行深度层监督，来引导早期的分类结果。我们发现，HED中这些潜在的技术得到的很好的性质，可以得到既准确，又计算高效的结果。

## 2. Holistically-Nested Edge Detection 整体嵌套边缘检测

In this section, we describe in detail the formulation of our proposed edge detection system. We start by discussing related neural-network-based approaches, particularly those that emphasize multi-scale and multi-level feature learning. The task of edge and object boundary detection is inherently challenging. After decades of research, there have emerged a number of properties that are key and that are likely to play a role in a successful system: (1) carefully designed and/or learned features [28, 5], (2) multi-scale response fusion [40, 32, 30], (3) engagement of different levels of visual perception [18, 27, 39, 17] such as mid-level Gestalt law information [7], (4) incorporating structural information (intrinsic correlation carried within the input data and output solution) [6] and context (both short- and long-range interactions) [38], (5) making holistic image predictions (referring to approaches that perform prediction by taking the image contents globally and directly) [25], (6) exploiting 3D geometry [15], and (7) addressing occlusion boundaries [16].

本节中，我们详细描述了我们提出的边缘检测系统的表述。我们开始先讨论一下相关的基于神经网络的方法，尤其是那些强调多尺度和多层次特征学习的。边缘和边界检测的任务本身就是非常有挑战性的。在几十年研究之后，已经出现了一些性质，非常关键，在一个成功的系统中很可能扮演重要角色：(1)仔细设计和/或学习到的特征，(2)多尺度响应融合，(3)不同层次的视觉感知的作用，如中层的Gestalt定律信息，(4)纳入结构信息（输入数据和输出的方案的内在相关性），和上下文（包括短程互动和长程互动），(5)进行整体的图像预测（指通过全局、直接的考虑图像内容，以进行预测），(6)探索3D几何，(7)处理遮挡的边界。

Structured Edges (SE) [6] primarily focuses on three of these aspects: using a large number of manually designed features (property 1), fusing multi-scale responses (property 2), and incorporating structural information (property 4). A recent wave of work using CNN for patch-based edge prediction [10, 34, 2, 19] contains an alternative common thread that focuses on three aspects: automatic feature learning (property 1), multi-scale response fusion (property 2), and possible engagement of different levels of visual perception (property 3). However, due to the lack of deep supervision (that we include in our method), the multi-scale responses produced at the hidden layers in [2, 19] are less semantically meaningful, since feedback must be back-propagated through the intermediate layers. More importantly, their patch-to-pixel or patch-to-patch strategy results in significantly downgraded training and prediction efficiency. By “holistically-nested”, we intend to emphasize that we are producing an end-to-end edge detection system, a strategy inspired by fully convolutional neural networks [26], but with additional deep supervision on top of trimmed VGG nets [36] (shown in Figure 3). In the absence of deep supervision and side outputs, a fully convolutional network [26] (FCN) produces a less satisfactory result (e.g. F-score .745 on BSD500) than HED, since edge detection demands highly accurate edge pixel localization. One thing worth mentioning is that our image-to-image training and prediction strategy still has not explicitly engaged contextual information, since constraints on the neighboring pixel labels are not directly enforced in HED. In addition to the speed gain over patch-based CNN edge detection methods, the performance gain is largely due to three aspects: (1) FCN-like image-to-image training allows us to simultaneously train on a significantly larger amount of samples (see Table 4); (2) deep supervision in our model guides the learning of more transparent features (see Table 2); (3) interpolating the side outputs in the end-to-end learning encourages coherent contributions from each layer (see Table 3).

Structured Edges (SE) [6]主要关注这些方面中的三个：使用大量手工设计的特征（性质1），融合了多尺度响应（性质2），纳入了结构信息（性质4）。最近很多使用CNN进行基于图像块的边缘预测，包含了另一条常用的线索，聚焦在三个方面：自动特征学习（性质1），多尺度响应融合（性质2），不同层次的视觉感知的可能作用（性质3）。但是，由于缺少深度监督（我们在我们的方法中总结得到的），隐含层生成的多尺度响应语义上的意义更少，因为反馈必须通过中间层进行反向传播。更重要的是，它们的图像块到像素，或图像块到图像块的策略，得到的训练和预测效率显著降低。通过“整体嵌套”，我们想要强调，我们提出的是一种端到端的边缘检测系统，这是一种由全卷积网络[26]启发得到的策略，但还有额外的在修剪的VGG网络上的深度监督（如图3所示）。如果没有深度监督和副输出，一个全卷积网络[26] (FCN)与HED相比，会得到不太令人满意的结果（在BSD500上的F-score为0.745），因为边缘检测需要高度精确的边缘像素定位。一个值得提到的事是，我们的图像到图像的训练和预测策略仍然没有显式的与上下文信息有关联，因为邻域像素标签的约束没有直接加入到HED中。与基于图像块的CNN边缘检测方法相比，除了速度提升外，性能的提升主要是由于三个方面：(1)FCN类的图像到图像的训练使我们可以同时在数量大的多的样本上进行训练（见表4）；(2)在我们模型上的深度监督，引导了更透明的特征的学习（见表2）；(3)在端到端的学习中，对副输出的插值，鼓励了每一层的连贯的贡献（见表3）。

### 2.1. Existing multi-scale and multi-level NN

Due to the nature of hierarchical learning in the deep convolutional neural networks, the concept of multi-scale and multi-level learning might differ from situation to situation. For example, multi-scale learning can be “inside” the neural network, in the form of increasingly larger receptive fields and downsampled (strided) layers. In this “inside” case, the feature representations learned in each layer are naturally multi-scale. On the other hand, multi-scale learning can be “outside” of the neural network, for example by “tweaking the scales” of input images. While these two variants have some notable similarities, we have seen both of them applied to various tasks.

由于CNN层次化学习的本质，多尺度和多层级学习可能会在不同的情况下不同。比如，多尺度学习可能是神经网络内在的，以越来越大的感受野和下采样层的形式存在。在这种“内在”的情况中，在每一层中学习到的特征表示很自然的就是多尺度的。另一方面，多尺度学习也可以在神经网络的外面，比如通过变化输入图像的尺度。由于这两种变体有一些值得注意的相似性，我们看到它们都应用到了各种不同的任务中。

We continue by next formalizing the possible configurations of multi-scale deep learning into four categories, namely, multi-stream learning, skip-net learning, a single model running on multiple inputs, and training of independent networks. An illustration is shown in Fig 2. Having these possibilities in mind will help make clearer the ways in which our proposed holistically-nested network approach differs from previous efforts and will help to highlight the important benefits in terms of representation and efficiency.

我们下面继续将可能的多尺度深度学习表述为四种类别，即，多流学习，跳跃网络学习，单模型多输入，独立网络的训练，如图2所示。知道有这些形式的存在，会帮助我们看的更清楚，我们提出的整体嵌套网络方法与之前的工作有多少不同，也会帮助强调表示和效率的重要优势。

Multi-stream learning [3, 29]: A typical multi-stream learning architecture is illustrated in Fig 2(a). Note that the multiple (parallel) network streams have different parameter numbers and receptive field sizes, corresponding to multiple scales. Input data are simultaneously fed into multiple streams, after which the concatenated feature responses produced by the various streams are fed into a global output layer to produce the final result.

多流学习：一个典型的多流学习架构如图2a所示。注意其中的多个（并行）网络流，有着不同的参数数量和感受野大小，对应着多个尺度。输入数据同时送入多个流中，然后多个流的特征响应进行拼接，送入一个全局输出层中，以产生最终的结果。

Skip-layer network learning: Examples of this form of network include [26, 14, 2, 33, 10]. The key concept in “skip-layer” network learning is shown in Fig 2(b). Instead of training multiple parallel streams, the topology for the skip-net architecture centers on a primary stream. Links are added to incorporate the feature responses from different levels of the primary network stream, and these responses are then combined in a shared output layer.

跳跃层网络学习：这种形式网络的例子包括[26, 14, 2, 33, 10]。跳跃层网络中的关键概念如图2b所示。网络没有训练多个并行的流，跳跃网络架构的拓扑主要是一个基本的流。加入了链接，以从基本网络流的不同层次中获取特征响应，这些响应然后接到到一个共享的输出层中。

A common point in the two settings above is that, in both of the architectures, there is only one output loss function with a single prediction produced. However, in edge detection, it is often favorable (and indeed prevalent) to obtain multiple predictions to combine the edge maps together.

上面两种设置的共同点是，在这两种架构中，只有一个输出损失函数，生成一个预测。但是，在边缘检测中，得到多个预测并将边缘图结合到一起，这是更好（更流行）的方法。

Single model on multiple inputs: To get multi-scale predictions, one can also run a single network (or networks with tied weights) on multiple (scaled) input images, as illustrated in Fig 2(c). This strategy can happen at both the training stage (as data augmentation) and at the testing stage (as “ensemble testing”). One notable example is the tied-weight pyramid networks [8]. This approach is also common in non-deep-learning based methods [6]. Note that ensemble testing impairs the prediction efficiency of learning systems, especially with deeper models[2, 10].

单个模型多个输入：为得到多尺度预测，我们可以在多个（不同尺度的）输入图像中运行单个网络，如图2c所示。这种策略可以在训练阶段中应用（如数据扩增），或在测试阶段（如集成测试）。一个值得注意的例子是，tied-weight金字塔网络。这种方法在非深度学习的方法中[6]也很常见。注意，集成测试会损害学习系统的预测效率，尤其是在更深的模型中[2,10]。

Training independent networks: As an extreme variant to Fig 2(a), one might pursue Fig 2(d), in which multi-scale predictions are made by training multiple independent networks with different depths and different output loss layers. This might be practically challenging to implement as this duplication would multiply the amount of resources required for training.

训练独立的网络：图2a的一种极端变体，就是图2d，其中通过训练多个独立的网络，有不同的深度和不同的输出损失层，来进行多尺度预测。这在实现起来可能有困难，因为这种重复性会使训练所需的资源加倍。

Holistically-nested networks: We list these variants to help clarify the distinction between existing approaches and our proposed holistically-nested network approach, illustrated in Fig 2(e). There is often significant redundancy in existing approaches, in terms of both representation and computational complexity. Our proposed holistically-nested network is a relatively simple variant that is able to produce predictions from multiple scales. The architecture can be interpreted as a “holistically-nested” version of the “independent networks” approach in Fig 2(d), motivating our choice of name. Our architecture comprises a single-stream deep network with multiple side outputs. This architecture resembles several previous works, particularly the deeply-supervised net[23] approach in which the authors show that hidden layer supervision can improve both optimization and generalization for image classification tasks. The multiple side outputs also give us the flexibility to add an additional fusion layer if a unified output is desired.

整体嵌套网络：我们列出这些变体，以澄清已有的方法和我们提出的整体嵌套网络的区别，如图2e所示。在现有的方法中，通常会有显著的冗余性，包括表示和计算复杂度上。我们提出的整体嵌套网络，是一种相对简单的变体，可以从多个尺度中生成预测。这种架构可以解释为，图2d中的独立网络方法的整体嵌套版本，这也是我们取名的动机。我们的架构由一个单流深度网络组成，有多个副输出。这种架构与之前的几个工作很像，尤其是深度监督网络[23]，其中作者表示，隐藏层的监督可以改进图像分类任务中的优化和泛化能力。多个副输出也使得我们有这个灵活性，如果期望一个统一的输出，就可以增加一个额外的融合层。

Figure 2. Illustration of different multi-scale deep learning architecture configurations: (a) multi-stream architecture; (b) skip-layer net architecture; (c) a single model running on multi-scale inputs; (d) separate training of different networks; (e) our proposed holistically-nested architectures, where multiple side outputs are added.

### 2.2. Formulation

Here we formulate our approach for edge prediction. 这里我们表述一下我们的边缘预测方法。

Training Phase: We denote our input training data set by S = {($X_n, Y_n$), n = 1,...,N}, where sample $X_n$ = {$x_j^{(n)}, j = 1,...,|X_n|$} denotes the raw input image and $Y_n$ = {$y_j^{(n)}, j = 1,...,|Y_n|$}, $y_j^{(n)}∈${0,1} denotes the corresponding ground truth binary edge map for image $X_n$. We subsequently drop the subscript n for notational simplicity, since we consider each image holistically and independently. Our goal is to have a network that learns features from which it is possible to produce edge maps approaching the ground truth. For simplicity, we denote the collection of all standard network layer parameters as W. Suppose in the network we have M side-output layers. Each side-output layer is also associated with a classifier, in which the corresponding weights are denoted as $w = (w^{(1)},...,w^{(M)})$. We consider the objective function

训练阶段：我们将输入训练数据集表示为S = {($X_n, Y_n$), n = 1,...,N}，其中样本$X_n$ = {$x_j^{(n)}, j = 1,...,|X_n|$}，表示原始输入图像，$Y_n$ = {$y_j^{(n)}, j = 1,...,|Y_n|$}, $y_j^{(n)}∈${0,1}表示$X_n$对应的真值二值边缘图。为表示简化，我们去掉下标n，因为我们将每幅图像进行整体、独立的考虑。我们的目标是有一个网络可以学习特征，其中可能生成边缘图，接近真值。为简化起见，我们将所有标准网络层的参数表示为W。假设网络中，我们有M个副输出层。每个副输出层都与一个分类器相关，其中对应的权重表示为$w = (w^{(1)},...,w^{(M)})$。我们考虑下面的目标函数：

$$L_{side}(W,w) = \sum_{m=1}^M α_m l_{side}^{(m)} (W,w^{(m)})$$(1)

where $l_{side}$ denotes the image-level loss function for side-outputs. In our image-to-image training, the loss function is computed over all pixels in a training image X = ($x_j$, j = 1,...,|X|) and edge map Y = ($y_j$,j = 1,...,|X|),$y_j$ ∈ {0,1}. For a typical natural image, the distribution of edge/non-edge pixels is heavily biased: 90% of the ground truth is non-edge. A cost-sensitive loss function is proposed in [19], with additional trade-off parameters introduced for biased sampling.

其中$l_{side}$表示副输出的图像级损失函数。在我们的图像到图像的训练中，损失函数是在训练图像X = ($x_j$, j = 1,...,|X|)和边缘图Y = ($y_j$,j = 1,...,|X|),$y_j$ ∈ {0,1}的所有像素中进行计算的。对于一个典型的自然图像，边缘/非边缘像素的分布是极度不均衡的：90%的真值是非边缘。[19]中提出了一种代价敏感的损失函数，提出了额外的折中参数进行有偏采样。

We instead use a simpler strategy to automatically balance the loss between positive/negative classes. We introduce a class-balancing weight β on a per-pixel term basis. Index j is over the image spatial dimensions of image X. Then we use this class-balancing weight as a simple way to offset this imbalance between edge and non-edge. Specifically, we define the following class-balanced cross-entropy loss function used in Equation (1)

相反，我们使用了一个更简单的策略，在正/负类别之间对损失进行均衡。我们在逐像素的项的基础上提出了一个类别均衡权重β。索引j是在图像X的图像空间维度上的。然后我们使用这个类别均衡加权作为一个简单的方法，来在边缘和非边缘之间补偿这种非均衡。具体的，我们定义下面的类别均衡的交叉熵损失函数，用于(1)中

$$l_{side}^{(m)}(W,w^{(m)}) = -β \sum_{j∈Y_+} log Pr(y_j=1 | X;W,w^{(m)}) - (1-β) \sum_{j∈Y_-} log Pr(y_j=0 | X; W, w^{(m)})$$(2)

where β = |Y_|/|Y| and 1-β = |Y+|/|Y|. |Y_| and |Y+| denote the edge and non-edge ground truth label sets, respectively. $Pr(y_j=1 | X; W, w^{(m)}) = σ(a_j^{(m)})∈[0,1]$ is computed using sigmoid function σ(⋅) on the activation value at pixel j. At each side output layer, we then obtain edge map predictions $\hat Y_{side}^{(m)} = σ(\hat A_{side}^{(m)})$, where $\hat A_{side}^{(m)} = \{ a_j^{(m), j=1,...,|Y|} \}$ are activations of the side-output of layer m.

其中β = |Y_|/|Y|，1-β = |Y+|/|Y|。|Y_|和|Y+|分别表示边缘和非边缘的真值标签集。$Pr(y_j=1 | X; W, w^{(m)}) = σ(a_j^{(m)})∈[0,1]$的计算是在像素j处的激活值上使用sigmoid函数σ(⋅)。在每个副输出层，我们然后得到边缘图预测$\hat Y_{side}^{(m)} = σ(\hat A_{side}^{(m)})$，其中$\hat A_{side}^{(m)} = \{ a_j^{(m), j=1,...,|Y|} \}$是副输出层m的激活。

To directly utilize side-output predictions, we add a “weighted-fusion” layer to the network and (simultaneously) learn the fusion weight during training. Our loss function at the fusion layer $L_{fuse}$ becomes

为直接使用副输出预测，我们对网络增加了一个“加权融合”层，并在训练时（同时）学习融合权重。我们在融合层的损失函数$L_{fuse}$为

$$L_{fuse}(W,w,h) = Dist(Y, \hat Y_{fuse}$$(3)

where $\hat Y_{fuse} = σ(\sum_{m=1}^M h_m \hat A_{side}^{(m)})$ where $h=(h_1,...,h_M)$ is the fusion weight. Dist(⋅,⋅) is the distance between the fused predictions and the ground truth label map, which we set to be cross-entropy loss. Putting everything together, we minimize the following objective function via standard (back-propagation) stochastic gradient descent:

其中$\hat Y_{fuse} = σ(\sum_{m=1}^M h_m \hat A_{side}^{(m)})$，其中$h=(h_1,...,h_M)$是融合权重。Dist(⋅,⋅)是融合的预测和真值标签图之间的距离，其中我们设为交叉熵损失。将所有事物放在一起，我们通过标准的（反向传播）随机梯度下降最小化下面的目标函数：

$$(W,w,h)^* = argmin(L_{side}(W,w)+L_{fuse}(W,w,h))$$(4)

See section 4 for detailed hyper-parameter and experiment settings. 见第4节详细的超参数和试验设置。

Testing phase: During testing, given image X, we obtain edge map predictions from both the side output layers and the weighted-fusion layer:

测试阶段：在测试时，给定图像X，我们从副输出层和加权融合层共同得到边缘图的预测：

$$(\hat Y_{fuse}, \hat Y_{side}^{(1)}, ..., \hat Y_{side}^{(M)}) = CNN(X, (W,w,h)^*)$$(5)

where CNN(·) denotes the edge maps produced by our network. The final unified output can be obtained by further aggregating these generated edge maps. The details will be discussed in section 4.

其中CNN(·)表示网络生成的边缘图。最终的联合输出，可以通过将这些生成的边缘图聚合到一起生成。细节将在第4部分讨论。

$$\hat Y_{HED} = Average(\hat Y_{fuse}, \hat Y_{side}^{(1)}, ..., \hat Y_{side}^{(M)})$$(6)

## 3. Network Architecture

Next, we describe the network architecture of HED.

### 3.1. Trimmed network for edge detection

The choice of hierarchy for our framework deserves some thought. We need the architecture (1) to be deep, so as to efficiently generate perceptually multi-level features; and (2) to have multiple stages with different strides, so as to capture the inherent scales of edge maps. We must also keep in mind the potential difficulty in training such deep neural networks with multiple stages when starting from scratch. Recently, VGGNet [36] has been seen to achieve state-of-the-art performance in the ImageNet challenge, with great depth (16 convolutional layers), great density (stride-1 convolutional kernels), and multiple stages (five 2-stride down-sampling layers). Recent work [2] also demonstrates that fine-tuning deep neural networks pre-trained on the general image classification task is useful to the low-level edge detection task. We therefore adopt the VGGNet architecture but make the following modifications: (a) we connect our side output layer to the last convolutional layer in each stage, respectively conv1_2, conv2_2, conv3_3, conv4_3, conv5_3. The receptive field size of each of these convolutional layers is identical to the corresponding side-output layer; (b) we cut the last stage of VGGNet, including the 5th pooling layer and all the fully connected layers. The reason for “trimming” the VGGNet is two-fold. First, because we are expecting meaningful side outputs with different scales, a layer with stride 32 yields a too-small output plane with the consequence that the interpolated prediction map will be too fuzzy to utilize. Second, the fully connected layers (even when recast as convolutions) are computationally intensive, so that trimming layers from pool5 on can significantly reduce the memory/time cost during both training and testing. Our final HED network architecture has 5 stages, with strides 1, 2, 4, 8 and 16, respectively, and with different receptive field sizes, all nested in the VGGNet. See Table 1 for a summary of the configurations of the receptive fields and strides.

我们的框架的层级结构的选择需要进行一些思考。我们需要架构(1)很深，这样才能高效的生成多级特征，(2)有带有不同步长的多个阶段，这样才能捕获边缘图的内在尺度。我们还要记住，从头开始训练这么深的多阶段神经网络是非常困难的。最近，VGGNet在ImageNet挑战中获得了目前最好的性能，深度很深（16个卷积层），很大的密度（步长为1的卷积核），而且是多阶段的（5个步长为2的下采样层）。最近的工作[2]也证明了，精调在通用图像分类任务中预训练的DNN，对于低层边缘检测任务是有用的。我们因此采用VGGNet架构，但进行了下面的修正：(a)我们将副输出层，与每个阶段的最后一个卷积层分别连接起来，即conv1_2, conv2_2, conv3_3, conv4_3, conv5_3。每个这个卷积层的感受野大小，与对应的副输出层是一样的；(b)我们去除掉了VGGNet的最后一个阶段，包括第5个pooling层，和所有的全连接层。修剪VGGNet的原因有两个。第一，因为我们需要不同尺度下的有意义的副输出，步长为32的层生成的输出空间上太小了，结果是插值的预测图太模糊不能用。第二，全连接层（即使重新转换成卷积层）计算量太大，所以去掉pool5以后的层可以显著降低训练和测试时的内存/时间。我们最后的HED网络架构有5个阶段，步长分别为1，2，4，8，16，有着不同的感受野大小，都是嵌套在VGGNet中的。见表1中的感受野和步长的配置总结。

### 3.2. Architecture alternatives

Below we discuss some possible alternatives in architecture design, and in particular, the role of deep supervision of HED for the edge detection task.

下面是一些可能的替代的架构设计，特别是，HED中带有深度监督进行边缘检测的任务。

**FCN and skip-layer architecture**. The topology used in the FCN model differs from that in our HED model in several aspects. As we have discussed, while FCN reinterprets classification nets for per-pixel prediction, it has only one output loss function. Thus, in FCN, although the skip net structure is a DAG that combines coarse, high-layer information with fine low-layer information, it does not explicitly produce multi-scale output predictions. We explore how this architecture can be used for the edge detection task under the same experimental setting as our HED model. We first try to directly apply the FCN-8s model by replacing the loss function with cross-entropy loss for edge detection. The results shown in first row of Table 2 are unsatisfactory, which is expected since this architecture is still not fine enough. We further explore whether the performance can be improved by adding even more links from low-level layers. We then create an FCN-2s network that adds additional links from the pool1 and pool2 layers. Still, directly applying the FCN skip-net topology falls behind our proposed HED architecture (see second row of Table 2). With heavy tweaking of FCN, there is a possibility that one might be able to achieve competitive performance on edge detection, but the multi-scale side-outputs in HED are seen to be natural and intuitive for edge detection.

**FCN和跳跃层架构**。FCN模型中使用的拓扑结构，与我们的HED模型有几个方面的不同。如同我们讨论的，FCN重新解释了分类网络进行逐像素预测，它只有一个输出损失函数。因此，在FCN中，虽然跳跃网络架构是一个DAG，结合了粗糙、高层的信息与精细的低层的信息，但它并没有显式的生成多尺度的输出预测。我们探索了这种架构，在与我们的HED模型一样的试验设置下，可以怎样用于边缘检测。我们首先尝试了直接应用FCN-8s模型，将损失函数替换为交叉熵，以进行边缘检测。表2的第一行给出了结果，表明并不令人满意，这是可以理解的，因为网络架构并不太精细。我们进一步探索了，是否可以通过从低层中添加更多的连接，来提升性能。我们然后创建了一个FCN-2s网络，从pool1和pool2层添加了更多的连接。直接应用FCN跳跃网络拓扑，还是比我们提出的HED架构要差一些（见表2中的第二行）。如果对FCN进行很大的改变，有可能在边缘检测中得到不错的结果，但HED中的多尺度副输出对于边缘检测来说是很自然的、很直观的。

**The role of deep supervision**. Since we incorporate a weighted-fusion output layer that connects each side-output layer, there is a need to justify the adoption of the deep supervision terms (specifically, $l_{side}(W, w^{(m)})$): now the entire network is path-connected and the output-layer parameters can be updated by back-propagation through the weighted-fusion layer error propagation path (subject to Equation 3). Here we show that deep supervision is important to obtain desired edge maps. The key characteristic of our proposed network is that each network layer is supposed to play a role as a singleton network responsible for producing an edge map at a certain scale. Here are some qualitative results based on the two variants discussed above: (1) training with both weighted-fusion supervision and deep supervision, and (2) training with weighted-fusion supervision only. We observe that with deep supervision, the nested side-outputs are natural and intuitive, insofar as the successive edge map predictions are progressively coarse-to-fine, local-to-global. On the other hand, training with only the weighted-fusion output loss gives edge predictions that lack such discernible order: many critical edges are absent at the higher layer side output; under exactly same experimental setup, the result on the benchmark dataset (row three of Table 2) differs only marginally in F-score but displays severely degenerated average precision; without direct control and guidance across multiple scales, this network is heavily biased towards learning large structure edges.

**深度监督的角色**。由于我们采用了一个加权融合输出层，将每个副输出层连接了起来，所以需要证明采用深度监督项的合理性（具体的，是$l_{side}(W, w^{(m)})$项）：现在整个网络的路径是连接起来的，输出层的参数可以通过反向传播，通过加权融合层的误差传播路径更新（相对于式3）。这里我们展示了深度监督对于得到期望的边缘图是很重要的。我们提出的网络的关键特征是，每个网络层都是单个网络的角色，负责生成一定尺度的特征图。这里有一些基于上述讨论的变体的定量结果：(1)使用加权融合监督和深度监督的训练，(2)只使用加权融合的监督的训练。我们观察到，在有深度监督的情况下，嵌套副输出是很自然的、很直观的，在目前的情况下，由于后续的边缘图预测是逐渐从粗糙到精细的，从局部到全局的。另一方面，只用加权融合输出损失进行训练，给出的边缘预测结果，缺少这样的可辨识的秩序：在更高层的副输出中，很多关键的边缘不见了；在严格相同的试验条件下，基准测试数据集上的结果（表2中的第3行）的F-score只有很少的不同，但展示出了严重降质的平均精度；在不同的尺度间没有直接的控制和引导，这个网络严重偏向于学习大型结构边缘。

## 4. Experiments

In this section we discuss our detailed implementation and report the performance of our proposed algorithm. 本节中，我们讨论详细的实现，给出我们提出的算法的性能。

### 4.1. Implementation

We implement our framework using the publicly available Caffe Library and build on top of the publicly available implementations of FCN[26] and DSN[23]. Thus, relatively little engineering hacking is required. In our HED system, the whole network is fine-tuned from an initialization with the pre-trained VGG-16 Net model.

我们使用Caffe实现我们的架构，并在开源的FCN和DSN上构建我们的框架。因此，需要的工程量不是太多。在我们的HED系统中，整个网络是用预训练的VGG-16网络模型初始化的，然后进行精调。

**Model parameters**. In contrast to fine-tuning CNN to perform image classification or semantic segmentation, adapting CNN to perform low-level edge detection requires special care. Differences in data distribution, ground truth distribution, and loss function all contribute to difficulties in network convergence, even with the initialization of a pre-trained model. We first use a validation set and follow the evaluation strategy used in [6] to tune the deep model hyper-parameters. The hyper-parameters (and the values we choose) include: mini-batch size (10), learning rate (1e-6), loss-weight $α_m$ for each side-output layer (1), momentum (0.9), initialization of the nested filters (0), initialization of the fusion layer weights (1/5), weight decay (0.0002), number of training iterations (10,000; divide learning rate by 10 after 5,000). We focus on the convergence behavior of the network. We observe that whenever training converges, the deviations in F-score on the validation set tend to be very small. In order to investigate whether including additional nonlinearity helps, we also consider a setting in which we add an additional layer (with 50 filters and a ReLU) before each side-output layer; we find that this worsens performance. On another note, we observe that our nested multi-scale framework is insensitive to input image scales; during our training process, we take advantage of this by resizing all the images to 400 × 400 to reduce GPU memory usage and to take advantage of efficient batch processing. In the experiments that follow, we fix the values of all hyper-parameters discussed above to explore the benefits of possible variants of HED.

**模型参数**。与精调CNN进行图像分类和语义分割相比，精调CNN进行低层边缘检测，需要特别的注意。即使在预训练模型的初始化的情况下，数据分布的差异，真值分布的差异，和损失函数的差异，都会影响网络收敛的难度。我们首先使用一个验证集，按照[6]中的评估策略来调节深度模型的超参数。超参数（和我们选择的值）包括：mini-batch的大小(10)，学习速率(1e-6)，每个副输出层的损失权重$α_m$(1)，动量(0.9)，嵌套滤波器的初始化(0)，融合层的权重的初始化(1/5)，权重衰减(0.0002)，训练迭代的次数（10000，5000次后学习速率除以10）。我们关注网络的收敛行为。我们观察到，不论什么时候训练收敛了，在验证集上的F-score的偏差一般就会很小。为研究是否包含额外的非线性会有帮助，我们也考虑了一种设置，在每个副输出层之前增加了一个额外的层（有50个滤波器和一个ReLU）；我们发现这会使得性能恶化。另一方面，我们观察到，嵌套多尺度框架对输入图像的尺度不敏感；在我们的训练过程中，我们利用这一点，将所有图像大小变为400 × 400，以降低GPU内存使用，并进行高效的批处理。在后续的试验中，我们固定所有上述讨论的超参数，以探索HED可能的变体的好处。

**Consensus sampling**. In our approach, we duplicate the ground truth at each side-output layer and resize the (down-sampled) side output to its original scale. Thus, there exists a mismatch in the high-level side-outputs: the edge predictions are coarse and global, while the ground truth still contains many weak edges that could even be considered as noise. This issue leads to problematic convergence behavior, even with the help of a pre-trained model. We observe that this mismatch leads to back-propagated gradients that explode at the high-level side-output layers. We therefore adjust how we make use of the ground truth labels in the BSDS dataset to combat this issue. Specifically, the ground truth labels are provided by multiple annotators and thus, implicitly, greater labeler consensus indicates stronger ground truth edges. We adopt a relatively brute-force solution: only assign a pixel a positive label if it is labeled as positive by at least three annotators; regard all other labeled pixels as negatives. This helps with the problem of gradient explosion in high level side-output layers. For low level layers, this consensus approach brings additional robustness to edge classification and prevents the network from being distracted by weak edges. Although not fully explored in our paper, a careful handling of consensus levels of ground truth edges might lead to further improvement.

**共识采样**。在我们的方法中，我们在每个副输出层中复制真值，并将（下采样的）副输出变换到其原始尺度大小。因此，在高层副输出中有误配：边缘预测是粗糙、全局的，而真值仍然包含很多弱边缘，可能会被认为是噪声。这个问题导致了有问题的收敛行为，即使在预训练模型的帮助下。我们观察到，这种误匹配导致，反向传播的梯度，在高层副输出的层会梯度爆炸。我们因此调整了，我们怎样利用BSDS数据集中的真值标签，以应用这个问题。具体的，真值标签是由多个标注者提供的，因此，隐含的有这样的结论，更多的标注者的共识标注，说明是更强的真值边缘。我们采用一个相对暴力的解决方案：只有当一个像素被至少三个标注者标注为正时，才给这个像素指定正的标签；认为其他所有的标注的像素都是负的。这帮助解决了高层副输出层的梯度爆炸的问题。对于更低的层，这种共识方法给边缘分类带来了额外的稳健性，防止网络被弱边缘干扰。虽然在本文中还没有完全进行探索，但真值边缘共识层次的仔细处理，肯定会带来进一步的改进。

**Data augmentation**. Data augmentation has proven to be a crucial technique in deep networks. We rotate the images to 16 different angles and crop the largest rectangle in the rotated image; we also flip the image at each angle, leading to an augmented training set that is a factor of 32 larger than the unaugmented set. During testing we operate on an input image at its original size. We also note that “ensemble testing” (making predictions on rotated/flipped images and averaging the predictions) yields no improvements in F-score, nor in average precision.

**数据扩增**。数据扩增已经证明是深度网络的一种关键技术。我们将图像旋转16种不同的角度，并从旋转的图像中剪切出最大的矩形。我们还在每个角度将图像进行翻转，得到了增广的训练集，比未增广的集大32倍。在测试时，输入图像不改变大小进行输入。我们还要说明，这种“集成测试”（在旋转的/翻转的图像上进行预测，并将预测进行平均）在F-score上没有改进，在平均精度而言也没有改进。

**Different pooling functions**. Previous work [2] suggests that different pooling functions can have a major impact on edge detection results. We conduct a controlled experiment in which all pooling layers are replaced by average pooling. We find that using average pooling decrease the performance to ODS=.741.

**不同的pooling函数**。之前的工作[2]表明，不同的pooling函数对边缘检测结果会有很大的影响。我们进行了受控的试验，其中所有的pooling层替换为平均pooling。我们发现使用平均pooling使性能降低到ODS=.741。

**In-network bilinear interpolation**. Side-output prediction upsampling is implemented with in-network deconvolutional layers, similar to those in [26]. We fix all the deconvolutional layers to perform linear interpolation. Although it was pointed out in [26] that one can learn arbitrary interpolation functions, we find that learned deconvolutions provide no noticeable improvements in our experiments.

**网络中的双线性插值**。副输出预测的上采样是用网络中解卷积层来实现的，与[26]中的类似。我们固定所有解卷积层进行线性插值。虽然要指出，在[26]中，可以学习到任意的插值函数，我们发现，学习好的解卷积在我们的试验中没有给出多少改进。

**Running time**. Training takes about 7 hours on a single NVIDIA K40 GPU. For a 320 × 480 image, it takes HED 400 ms to produce the final edge map (including the interface overhead), which is significantly faster than existing CNN-based methods [34, 2]. Some previous edge detectors also try to improve performance by the less desirable expedient of sacrificing efficiency (for example, by testing on input images from multiple scales and averaging the results).

**运行时间**。在单个NVidia K40 GPU上，训练耗时大约7个小时。对于320 × 480的图像，HED耗时400ms产生最终的边缘图（包括接口的耗时），比现有的基于CNN的方法要快的多。一些之前的边缘检测器试图通过一些权宜之计牺牲效率来提升性能（比如，对输入图像在不同尺度上进行测试，将结果进行平均）。

### 4.2. BSDS500 dataset

We evaluate HED on the Berkeley Segmentation Dataset and Benchmark (BSDS 500) [1] which is composed of 200 training, 100 validation, and 200 testing images. Each image has manually annotated ground truth contours. Edge detection accuracy is evaluated using three standard measures: fixed contour threshold (ODS), per-image best threshold (OIS), and average precision (AP). We apply a standard non-maximal suppression technique to our edge maps to obtain thinned edges for evaluation. The results are shown in Figure 5 and Table 4.

我们在BSDS500上评估HED，数据集由200幅训练图像，100幅验证图像，和200幅测试图像构成。每幅图像都有手工标注的真值轮廓。边缘检测准确率使用三种标准度量来评估：固定轮廓阈值(ODS)，每幅图像最佳阈值(OIS)，和平均精度(AP)。我们对边缘图使用标准的非极大抑制技术，来得到细化的边缘进行评估。结果如图5和表4所示。

**Side outputs**. To explicitly validate the side outputs, we summarize the results produced by the individual side-outputs at different scales in Table 3, including different combinations of the multi-scale edge maps. We emphasize here that all the side-output predictions are obtained in one pass; this enables us to fully investigate different configurations of combining the outputs at no extra cost. There are several interesting observations from the results: for instance, combining predictions from multiple scales yields better performance; moreover, all the side-output layers contribute to the performance gain, either in F-score or averaged precision. To see this, in Table 3, the side-output layer 1 and layer 5 (the lowest and highest layers) achieve similar relatively low performance. One might expect these two side-output layers to not be useful in the averaged results. However this turns out not to be the case — for example, the Average 1-4 achieves ODS=.760 and incorporating the side-output layer 5, the averaged prediction achieves an ODS=.774. We find similar phenomenon when considering other ranges. As mentioned above, the predictions obtained using different combination strategies are complementary, and a late merging of the averaged predictions with learned fusion-layer predictions leads to the best result. Another observation is, when compared to previous ”non-deep” methods, performance of all ”deep” methods drops more in the high recall regime. This might indicate that deep learned features are capable of (and favor) learning the global object boundary — thus many weak edges are omitted. HED is better than other deep learning based methods in the high recall regime because deep supervision helps us to take the low level predictions into account.

**副输出**。为显式的验证副输出，我们在表3中总结了不同尺度中单个副输出的结果，包括多尺度边缘图的不同组合。我们这里强调，所有的副输出预测都是一次性得到的；这使我们可以不需要额外代价的，完整的研究输出组合的不同配置。从这些结果中可以有几个很有趣的观察：比如，综合多个尺度的预测会得到更好的结果；而且，所有的副输出层都会性能提升有所贡献，要么是F-score，或者平均精度。为看到这个结果，在表3中，副输出层1和层5（最低和最高的层）得到了类似但较低的性能。那么这两个副输出层可能在平均的结果中不太有用。但是，结果并不是这个情况，比如，1-4层的平均得到ODS=0.760，但将副输出层5的结果纳入进来后，得到的平均预测为ODS=0.774。我们发现在考虑其他范围时也有类似的结果。前面提到过，使用不同的组合策略得到的预测是互补的，平均的预测与学习到的融合层预测的后期融合，会得到更好的结果。另一个观察是，当与之前的非深度学习方法相比，所有深度学习的方法在高recall的领域中会有很大的跌落。这可能说明，深度学习学到的特征可以学习到全局的目标边缘，因此弱边缘就被忽略了。HED比其他的基于深度学习的方法，在高recall的领域中都要更好，因为深度监督帮助我们纳入了低层的预测。

**Late merging to boost average precision**. We find that the weighted-fusion layer output gives best performance in F-score. However the average precision degrades compared to directly averaging all the side outputs. This might due to our focus on “global” object boundaries for the fusion-layer weight learning. Taking advantage of the readily available side outputs in HED, we merge the fusion layer output with the side outputs (at no extra cost) in order to compensate for the loss in average precision. This simple heuristic gives us the best performance across all measures that we report in Figure 5 and Table 4.

**后期融合可以提升平均精度**。我们发现加权融合层输出给出了F-score最好的性能。但是与直接平均所有的副输出相比，AP下降了。这可能是因为，对融合层加权学习，我们关注的是全局目标边缘。利用HED的副输出，我们将融合层的输出与副输出进行了融合（没有任何额外代价），以补偿AP的损失。这种简单的启发式在所有指标中都得到了最好性能，见图5和表4。

**More training data**. Deep models have significantly advanced results in a variety of computer vision applications, at least in part due to the availability of large training data. In edge detection, however, we are limited by the number of training images available in the existing benchmarks. Here we want to explore whether adding more training data will help further improve the results. To do this, we expand the training set by randomly sampling 100 images from the test set. We then evaluate the result on the remaining 100 test images. We report the averaged result over 5 such trials.

**更多的训练数据**。深度模型在很多计算机视觉应用中都有明显更好的结果，部分是因为有大型训练数据。在边缘检测中，现有的基准测试的可用训练图像是有限的。这里我们希望探索，增加更多的训练数据，是否会进一步改进结果。为做到这个，我们拓展训练数据集的方法是，随机从测试集中取样100幅图像。我们然后在剩下的100幅测试图像中评估结果。我们经过5次这样的尝试，给出了平均的结果。

We observe that by adding only 100 training images, performance improves from ODS=.782 to ODS=.797 (±.003), nearly touching the human benchmark. This shows a potentially promising direction to further enhance HED by training it with a larger dataset.

我们观察到，增加了100幅训练图像，性能从ODS=.782改进到了ODS=.793(±.003)，几乎达到了人类的基准性能。这说明在更大的数据集中训练，是增强HED的一个有希望的方向。

### 4.3. NYUDv2 Dataset

The NYU Depth (NYUD) dataset [35] has 1449 RGB-D images. This dataset was used for edge detection in [31] and [11]. Here we use the setting described in [6] and evaluate HED on data processed by [11]. The NYUD dataset is split into 381 training, 414 validation, and 654 testing images. All images are made to the same size and we train our network on full resolution images. As used in [12, 6], during evaluation we increase the maximum tolerance allowed for correct matches of edge predictions to ground truth from .0075 to .011.

NYUD数据集有1499幅RGB-D图像。这个数据集在[31,11]中用于边缘检测。这里我们使用[6]中的设置，在[11]中处理的数据上评估HED。NYUD数据集分割成381幅训练图像，414幅验证图像，654幅测试图像。所有图像都改变成同样的大小，网络的训练是在完整的分辨率图像上进行的。在评估时，我们增加了边缘预测的与真值正确匹配的最大容忍度，从.0075到.011，[12,6]中也是这样使用的。

**Depth information encoding**. Following the success in [12] and [26], we leverage the depth information by utilizing HHA features in which the depth information is embedded into three channels: horizontal disparity, height above ground, and angle of the local surface normal with the inferred direction of gravity. We use the same HED architecture and hyper-parameter settings as were used for BSDS 500. We train two different models in parallel, one on RGB images and another on HHA feature images, and report the results below. We directly average the RGB and HHA predictions to produce the final result by leveraging RGB-D information. We also tried other approaches to incorporate the depth information, for example, by training on the raw depth channel, or by concatenating the depth channel with the RGB channels before the first convolutional layer. None of these attempts yields notable improvement compared to the approach using HHA. The effectiveness of the HHA features shows that, although deep neural networks are capable of automatic feature learning, for depth data, carefully hand-designed features are still necessary, especially when only limited training data is available.

**深度信息编码**。按照[12,26]中的成功，我们通过利用HHA特征来利用深度信息，其中深度信息嵌入到了三个通道中：水平差异，离地高度，局部平面法线与推断的重力方向的角度。我们使用相同的HED架构，相同的超参数设置。我们同时并行训练两个不同的模型，一个在RGB图像中，另一个在HHA特征图中，并在下面给出结果。我们直接平均了RGB和HHA的预测，以得到最终的结果。我们还尝试了其他方法，以纳入深度信息，比如，在原始深度通道中进行训练，或通过将深度通道与RGB通道拼接在一起，送入第一个卷积层。这些方法与使用HHA的方法相比，都没有得到很明显的改进。HHA特征的有效性说明，尽管DNN可以自动学习特征，但对于深度数据，仔细手工设计的特征仍然是必须的，尤其是只有很少的训练数据下。

Table 5 and Figure 6 show the precision-recall evaluations of HED in comparison to other competing methods. Our network structures for training are kept the same as for BSDS. During testing we use the Average2-4 prediction instead of the Fusion-layer output as it yields the best performance. We do not perform late merging since combining two sources of edge map predictions (RGB and HHA) already gives good average precision. Note that the results achieved using the RGB modality only are already better than those of the previous approaches.

表5和图6表明，HDE与其他方法的相比的精度-recall评估。我们的网络架构的训练，与BSDS是一样的。在测试时，我们使用2-4层的平均预测，而没有使用融合层的输出，因为这样得到了最好的性能。我们没有进行后期融合，因为将这两种边缘图预测组合起来(RGB and HHA)已经得到了很好的AP。注意，使用RGB模态得到的结果已经比之前的启发方法要好了。

## 5. Conclusion

In this paper, we have developed a new convolutional-neural-network-based edge detection system that demonstrates state-of-the-art performance on natural images at a speed of practical relevance (e.g., 0.4 seconds using GPU and 12 seconds using CPU). Our algorithm builds on top of the ideas of fully convolutional neural networks and deeply-supervised nets. We also initialize our network structure and parameters by adopting a pre-trained trimmed VGGNet. Our method shows promising results in performing image-to-image learning by combining multi-scale and multi-level visual responses, even though explicit contextual and high-level information has not been enforced. Source code and pretrained models are available online at https://github.com/s9xie/hed.

本文中，我们提出了一种新的基于CNN的边缘检测系统，在自然图像中得到了目前最好的结果，速度也非常的快（在GPU上为0.4s，在CPU上为12s）。我们的算法是在全卷积CNN和深度监督网络的思想上构建起来的。我们采用修剪的预训练的VGGNet对网络参数和超参数进行了初始化。我们的方法在进行图像到图像的学习中，通过结合了多尺度和多级别的视觉响应，得到了很有希望的结果，而显式的上下文信息和高层信息并没有加入到其中。代价和预训练模型已经开源。