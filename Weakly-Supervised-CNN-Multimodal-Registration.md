# Weakly-Supervised Convolutional Neural Networks for Multimodal Image Registration

Yipeng Hu et. al. University College London etc.

## 0. Abstract

One of the fundamental challenges in supervised learning for multimodal image registration is the lack of ground-truth for voxel-level spatial correspondence. This work describes a method to infer voxel-level transformation from higher-level correspondence information contained in anatomical labels. We argue that such labels are more reliable and practical to obtain for reference sets of image pairs than voxel-level correspondence. Typical anatomical labels of interest may include solid organs, vessels, ducts, structure boundaries and other subject-specific ad hoc landmarks. The proposed end-to-end convolutional neural network approach aims to predict displacement fields to align multiple labelled corresponding structures for individual image pairs during the training, while only unlabelled image pairs are used as the network input for inference. We highlight the versatility of the proposed strategy, for training, utilising diverse types of anatomical labels, which need not to be identifiable over all training image pairs. At inference, the resulting 3D deformable image registration algorithm runs in real-time and is fully-automated without requiring any anatomical labels or initialisation. Several network architecture variants are compared for registering T2-weighted magnetic resonance images and 3D transrectal ultrasound images from prostate cancer patients. A median target registration error of 3.6 mm on landmark centroids and a median Dice of 0.87 on prostate glands are achieved from cross-validation experiments, in which 108 pairs of multimodal images from 76 patients were tested with high-quality anatomical labels.

监督学习进行多模态图像配准的一个基本挑战是，缺少体素级的空间对应性的真值。本文描述的一种方法，从解剖标签中所包含的更高层的对应性信息中，推断体素级的变换。我们认为这种标签更加可靠，更加实际，比体素级的对应性更加可以得到图像对的参考集。典型的感兴趣解剖标签可能包含固体器官，血管，导管，结构边缘和其他目标特定的ad hoc特征点。提出的端到端的CNN，目标是对图像对在训练时，预测偏移场，以对齐多标签的对应结构，同时用无标注的图像对作为网络输入进行推理。我们强调了提出的策略的用途广泛，在训练时利用了多种类型的解剖标签，不需要在所有训练图像对中可以辨认。在推理时，得到的3D变形图像配准算法实时运行，完全自动的，不需要任何解剖标签或初始化。几种网络架构变体进行了比较，将T2-MRI与3D 经直肠超声图像进行配准，对前列腺癌患者。交叉验证试验得到了，对前列腺，特征点重心TRE中值为3.6mm，中值Dice为0.87，其中76位患者的108对多模态图像用高质量解剖结构进行了测试。

Keywords: medical image registration; image-guided intervention; convolutional neural network; weakly-supervised learning; prostate cancer.

## 1. Introduction

Multimodal image registration aims to spatially align medical images produced from different imaging modalities. Among many other medical imaging applications, this is useful in minimally- or none-invasive image-guided procedures, in which a common strategy is to fuse the detailed diagnostic information from quality pre-procedural images with intra-procedural imaging that is typically restricted by the interventional requirements, such as portability, accessibility, temporal resolution, limited field of view and controlled dosage for contrast agent or radiation.

多模图像配准的目标是，将不同模态生成的医学图像进行空间对齐。在很多其他医学成像应用中，这对非侵入性或侵入性最小的图像引导手术是很有用的，其中的一个常见策略是，将质量很好的术前诊断图像，与术中成像进行融合，而术中成像通常是受到介入需要的典型约束，如可移动性、可访问性、时间分辨率，有限的视野和对比剂或剂量的受控剂量。

Classical pairwise intensity-based image registration methods are in general based on optimising image similarity, a metric indicating how well image intensities correspond (Hill et al., 2001). However, in many interventional applications, engineering a multimodal similarity metric that is sufficiently robust for clinical use is challenging. Potential difficulties include: 1) different physical acquisition processes may generate statistical correlation between imaging structures that do not correspond to the same anatomical structures, violating one of the underlying assumptions for most intensity-based similarity measures (Zöllei et al., 2003); 2) the spatial and temporal variabilities in the intra-procedural imaging, partly due to user-dependency (Noble, 2016), is complex to summarise with simple statistical properties or information-theory-based measures; and 3) intraoperative time constraints prevent the use of better imaging quality as it typically requires significant imaging or processing time, as well as the use of computationally-intensive approaches, such as exhaustive global optimisation.

经典的成对的基于灰度的图像配准方法，一般是基于图像相似度的最优化原理的，图像相似度度量，指示的是图像灰度对应的程度。但是，在很多介入应用中，设计一个多模相似度度量，对于临床使用来说足够稳健，这是很有挑战的事情。潜在的困难包括：1)不同的物理获取过程，可能会在并不是对应着同样的解剖结构的成像结构中生成统计上的相关性，这与大多数基于灰度的相似度度量的潜在假设是相矛盾的；2)术中成像在空间上和时间上都有一些变化，部分是因为这是依赖于用户的，这很难用简单的统计性质或基于信息论的度量来总结；3)术中的时间约束，阻碍了更好的成像质量的使用，因为这通常需要显著的成像或处理时间，一般也不会使用计算很密集的方法，如穷举式的全局优化。

Alternative feature-based image registration methods, when features are extracted automatically, face similar challenges. Manual anatomical feature selection for registration is user-dependent and often costly or even infeasible intraoperatively but arguably remains the most robust method for multimodal image registration for many intra-procedural applications (Viergever et al., 2016). Semi-automated or assisted medical image segmentation is a promising research direction to support registration (Wang et al., 2017), but it has not yet demonstrated clinical value in fast evolving interventional applications.

另外的基于特征的图像配准方法，当特征是自动提取时，面临的类似的挑战。手动选择解剖结构进行配准，依赖于用户，通常很费时，甚至在术中是不可行的，但仍然是最稳健的多模图像配准方法，尤其是在很多术中应用中。半自动的或辅助医学影像分割是一种很有希望的研究方向，可以支持配准，但目前还没有在快速演进的介入应用中证明其临床价值。

In this work, we focus on one exemplar application of interventional multimodal image registration which is to register pre-procedural multi-parametric magnetic resonance (MR) images to intra-procedural transrectal ultrasound (TRUS) images for prostate cancer patients (Pinto et al., 2011; Rastinehad et al., 2014; Siddiqui et al., 2015). Multi-parametric MR imaging (Dickinson et al., 2011), including recent development of hyperpolarised imaging (Wilson and Kurhanewicz, 2014) and computational methods based on diffusion-weighted imaging (Panagiotaki et al., 2015), have shown favourable results in diagnosing and staging prostate cancer. This has already been recommended to form a part of a standard clinical pathway in some countries, including the UK (Vargas et al., 2016). On the intra-procedural side, TRUS imaging is routinely used for guiding the majority of targeted biopsies and focal therapies, but it provides limited value in differentiating cancerous tissue from healthy surroundings. Fusing the MR and TRUS images, can enable accurate detection, localisation and treatment of low- to medium-risk disease in TRUS-guided procedures (Valerio et al., 2015). However, like most other ultrasound-guided medical procedures, this represents a typical example where no robust image similarity measure has been demonstrated. For example, anatomically different imaging structures, such as the prostate inner-outer gland separation, a cleavage plane known as the surgical capsule, defined on TRUS images (Ethan J. Halpern, 2008) and the central-peripheral zonal boundary visible on MR images, appear as being similar in the two types of images and thus possess strong statistical correlation between them. This leads to false alignment using most, if not all, of the established intensity-based similarity measures and the associated registration methodologies, such as the work by Rueckert et al. (Rueckert et al., 1999).

本文中，我们关注一个介入多模图像配准的样本应用，将术前的多参数MRI图像与术中的经直肠超声(TRUS)图像进行配准，用于前列腺肿瘤患者。多参数MRI，包括最近的hyperpolarised成像的最近进展，和基于diffusion-weighted成像的计算方法，在前列腺肿瘤的诊断和确定阶段中有很好的结果。在一些国家，包括UK，这已经被推荐为标准临床方法的一部分。在术中方面，TRUS成像是引导目标活检和局部疗法的常规方法，但对于区分肿瘤组织与健康组织方面则只有有限的价值。将MR与TRUS图像融合，可以在TRUS引导手术中对低风险和中风险的疾病进行精确的检测，定位和治疗。但是，与多数其他超声引导的医学手术类似，这代表了一个典型的例子，其中没有很稳健的图像相似度度量。比如，解剖上不同的成像结构，比如前列腺内部-外部腺体的分离，这是一个差异面，已知为surgical capsule，在TRUS图像上比较清晰，和在MRI图像中可见的central-peripheral zonal边缘，在这两种图像中看起来很像，因此两者之间有很强的统计相关性。这如果用传统的基于灰度的相似度度量和相关的配准方法，会带来假对齐。

To alleviate some of the aforementioned problems from both the intensity- and feature-based methods in registration applications of this type, a class of model-to-image fusion methods have been proposed (Hu et al., 2012; Khallaghi et al., 2015; van de Ven et al., 2015; Wang et al., 2016a), in which motion models of the prostate glands obtained from MR image are aligned to the surface of the gland capsule automatically or semi-automatically. These methods suffer from two limitations. First, the subject-specific pairwise registration requires correspondent features to be extracted from both images. We previously argued that the only common features of the prostate gland that are consistently available from both images are the capsule surface while ad hoc landmarks can be found on a case-by-case basis for validation purpose (Hu, 2013). Indeed, the gland boundary has been the feature of interest to match in most of these mentioned algorithms. Second, partly as a result of the availability of the sparse features, some form of a motion prior is required to regularise the non-rigid registration methods (De Silva et al., 2017; Hu et al., 2015, 2011; Khallaghi et al., 2015; Wang et al., 2016b). The learning of the motion models is highly application-dependent and usually not generalisable to other medical applications or different imaging protocols for the same application, such as pathological cases or interventions with different surgical instruments.

为缓解前述的基于灰度的和基于特征的配准方法的部分问题，，提出了一类模型到图像的融合方法，其中MRI图像得到的前列腺的运动模型，与gland capsule的表面自动的或半自动的对齐。这些方法有两种局限。第一，特定对象的成对配准，需要从两幅图像中提取对应的特征。我们之前认为，只有在两幅图像中都一致可用的前列腺的常见特征，是capsule surface，而在一例一例上发现的ad hoc特征点只用做验证目的。确实，腺体边缘是感兴趣的特征，可以匹配多数之前提到的算法。第二，部分是稀疏特征的可用性的结果，需要一些运动先验的形式来对非刚体配准方法进行正则化。运动模型的学习是高度依赖于应用的，通常不能泛化到其他医学应用中，或同一个应用的其他成像协议中，比如病理的情况，或用不同的手术设备的介入。

Supervised representation learning (Bengio et al., 2013), especially methods using convolutional neural networks (LeCun et al., 2015, 1998), has the potential to optimise medical image representation in a regression network that predicts spatial correspondence between a pair of given images, without human-engineered image features or intensity-based similarity measures. However, voxel-level ground-truth for learning correspondence are scarce and, in most scenarios, impossible to reliably obtain from medical image data. Alternative methods to learn similarity measures, e.g. (Simonovsky et al., 2016), also require non-trivial ground-truth labels and, to our best knowledge, have not been proposed for registering MR and ultrasound images. Several methods have been proposed to procure large numbers of pseudo-ground-truth transformations for training, such as those from simulations (Krebs et al., 2017; Miao et al., 2016; Sokooti et al., 2017), existing registration methods (Rohé et al., 2017) or manual rigid alignment (Liao et al., 2017). Recently-proposed machine-learning-based image registration methods have relied on image-similarity-driven unsupervised learning (Cao et al., 2017; de Vos et al., 2017; Wu et al., 2013; Yang et al., 2017), meaning that these methods inherit the key shortcomings of classical intensity-based image registration algorithms.

监督表示学习，尤其是使用CNN的方法，可以在回归网络中优化医学图像表示，预测一对给定图像的空间对应性，不需要人类设计的图像特征，或基于灰度的相似度度量。但是，用于学习对应性的体素级的真值是很稀少的，在多数场景中，从医学图像数据中不能很可靠的得到。其他的学习相似性度量的方法，如(Simonovsky et al., 2016)，也需要真值标签，而且据我们所知，并没有用于配准MR和US图像。提出了几种方法来设法得到大量伪真值变换进行训练，如采用仿真，从现有的配准方法得到，或手动刚性配准。最近提出的基于机器学习的图像配准方法，依赖于图像相似度推动的无监督学习，意味着这些方法继承了经典的基于灰度的图像配准方法的关键缺点。

We argue that higher-level corresponding structures are much more practical to annotate reliably with anatomical knowledge. Such labels can be used to highlight in pairs of images the same organs and boundaries between them, pathological regions, and other anatomical structures, morphological or physiological features appearing in both images, and can serve as weak labels for training the prediction of lower-level voxel correspondence. Moreover, subject-specific landmarks that are only inconsistently available from all image pairs may also contribute to finding detailed voxel correspondence, especially from interventional data. For instance, spatial distributions of calcification scatters and water-based cysts are highly patient-specific (see an example in Fig.1). Although readily identifiable in many pairs, they have mostly been used for validation purposes (Hu et al., 2012; van de Ven et al., 2013; Wang et al., 2016a). In this work, we introduce a novel framework which uses these anatomical labels and full image voxel intensities as training data, to enable a fully-automatic, deformable image registration that requires only unlabelled image data during inference.

我们认为，更高层次的对应结构，因为有解剖结构信息，可以更可靠的进行标注，这是更实际的做法。这些标签可以用于在成对图像中强调它们之间同样的器官和边缘，在两幅图像都出现的病理区域，其他解剖结构，形态学或生理学上的特征，也可以作为弱标签，用于训练低层体素级的对应性的预测。而且，特定对象的特征点，在所有图像对中并不是一致可用的，也可以对找到细节体素对应性有所贡献，尤其是那些从介入数据中得到的。比如，calcification scatters和water-based cysts的空间分布是高度依赖于患者的（见图1中的例子）。虽然在很多图像对中可以发现，但它们主要是用作验证的目的的。本文中，我们提出一种新的框架，使用这些解剖标签和完整的图像体素灰度作为训练数据，得到一个全自动的形变图像配准方法，在推理时，只需要无标注的图像。

Initial results were reported in an abstract on our preliminary work (Hu et al., 2018). We summarise the substantially extended contributions contained in this paper: 1) a detailed methodology description for the weakly-supervised image registration framework is presented in Section 2.1; 2) a new efficient multiscale Dice for weakly-supervised registration network training is described in Section 2.2; 3) a novel memory-efficient network architecture is proposed without using the previously proposed global affine sub-network in Section 2.3; and 4) rigorous analysis comparing different network variations and classical pairwise registration algorithms are reported in Section 4 and significantly improved results are also presented.

初始的结果给出了我们的初步工作的摘要。我们在本文中总结了这个拓展了很多的贡献：1)提出了一种详细的弱监督图像配准框架，2)提出了一种用于弱监督配准网络训练的新的高效的多尺度Dice，3)提出了一种新的不太占用内存的网络架构，不需要使用之前提出的全局仿射子网络，4)对不同的网络变化和经典的成对配准算法进行了严格的分析对比，给出了显著改进的结果。

## 2. Method

### 2.1 A Weakly-Supervised Image Registration Framework

Given N pairs of training moving- and fixed images, $x^A$ = {$x_n^A$} and $x^B$ = {$x_n^B$}, respectively, n = 1,...,N. On the nth image pair, $M_n$ pairs of moving- and fixed labels $l^A$ = {$l_{mn}^A$} and $l^B$ = {$l_{mn}^B$} represent corresponding regions of anatomy, $m = 1, ..., M_n$. We formulate the training of a neural network to predict the voxel correspondence, which is represented by a dense displacement field (DDF) $u_n$, as a weakly-supervised learning problem that maximises a utility function indicating the expected label similarity over training image pairs:

给定N对训练用的移动和固定图像，分别是$x^A$ = {$x_n^A$}和$x^B$ = {$x_n^B$}，n = 1,...,N。在第n对图像中，$M_n$对移动和固定标签$l^A$ = {$l_{mn}^A$}和$l^B$ = {$l_{mn}^B$}，代表了对应的解剖区域，$m = 1, ..., M_n$。我们将网络的训练以预测体素对应性（由一个密集偏移场DDF表示）的问题，表述为一个弱监督学习问题，对在整个训练图像对上的期望标签相似性的指示效用函数进行最大化：

$$J = \frac{1}{N} \sum_{n=1}^N \frac{1}{M_n} \sum_{m=1}^{M_n} J_{mn} (l_{mn}^B, y_{mn}^A)$$(1)

where the inner summation represents the image-level label similarity, averaging a label-level similarity measure over $M_n$ labels associated with the nth image pair. In this work, the label-level similarity is computed between the fixed label $l_{mn}^B$ and the spatially warped moving label $y_{mn}^A = f_T(l_{mn}^A, u_n)$ with the displacements u = {$u_n(x_n^A, x_n^B, θ)$} being predicted by the neural network parameterised by θ, as illustrated in Fig.2. The network training aims to minimise the negative utility function balanced with a deformation regularisation Ω(u) penalising non-smooth displacements, weighted by a hyper-parameter α:

其中内部求和表示图像级的标签相似性，对第n对图像，标签级的相似性度量在$M_n$个标签上进行平均。本文中，标签级的相似性是在固定标签$l_{mn}^B$和空间变形的移动标签$y_{mn}^A = f_T(l_{mn}^A, u_n)$上进行计算的，偏移u = {$u_n(x_n^A, x_n^B, θ)$}是神经网络预测得到的，神经网络参数为θ，如图2所示。网络训练的目标是，最小化负的效用函数与形变正则化Ω(u)的和，Ω(u)惩罚的是非平滑位移，这两项通过α加权：

$$\hat θ = argmin_θ [-J(x^A, x^B, l^A, l^B;θ)+α⋅Ω(u)]$$(2)

As motivated in the Introduction, we emphasize that such a loss does not incorporate any intensity-based similarity term which is proven to be unreliable in our application. During training, we use a standard stochastic K-minibatch gradient descent optimisation (Goodfellow et al., 2016) which requires an unbiased estimator of the additive batch gradients in each minibatch $\frac {\widehat {∂J}}{∂θ} = \frac {1}{K} \sum_{k=1}^K \frac {\widehat {∂J_k}}{∂θ}$, k=1,...,K. To avoid the non-trivial computation of minibatch gradients with a variable number of labels and to simplify the implementation, we propose to construct such a gradient estimator by a two-stage sampling: K image pairs are sampled uniformly in the first stage, then in second stage single label pairs are sampled uniformly from those associated with the previously-sampled image pairs. With this approach, each minibatch contains an equal number of K image-label pairs, from which $\frac {\widehat {∂J_k}}{∂θ}$ is estimated. Given the first-stage-sampled image pairs, let’s consider $E_2(\frac {\widehat {∂J_k}}{∂θ}) = \frac {∂J_k}{∂θ}$ as the conditional expectation of the estimated gradients over the label pairs sampled in the second stage. With the first-stage expectation $E_1[⋅]$ over image pairs, it can be shown that the minibatch gradients $\frac {\widehat {∂J}}{∂θ}$ computed from the two-stage clustering sampling is unbiased:

如同在引言中所述，我们强调这个损失并没有将基于灰度的相似性项纳入进来，而这种项在我们的应用中是不可靠的。在训练中，我们使用标准的随机K-minibatch梯度下降优化，需要在每个minibatch中的加性批梯度的无偏估计$\frac {\widehat {∂J}}{∂θ} = \frac {1}{K} \sum_{k=1}^K \frac {\widehat {∂J_k}}{∂θ}$, k=1,...,K。为避免大量计算可怜数量标签的minibatch梯度，并简化其实现，我们提出通过两步采样构建这样一个梯度估计器：在第一阶段对K个图像对进行均匀采样，在第二阶段，从那些与之前采样的图像对相关的之中，对单个标签进行均匀采样。采用这种方法，每个mini-batch包含同样数量的K个图像标签对，从中对$\frac {\widehat {∂J_k}}{∂θ}$进行估计。给定第一阶段采样的图像对，我们考虑$E_2(\frac {\widehat {∂J_k}}{∂θ}) = \frac {∂J_k}{∂θ}$为，估计的梯度在第二阶段的标记对上的条件期望。有了第一阶段在图像对中的期望$E_1[⋅]$，可以说明，两阶段聚类采样的minibatch梯度$\frac {\widehat {∂J}}{∂θ}$是无偏的：

$$E(\frac {\widehat {∂J}}{∂θ}) = E_1 [E_2(\frac {\widehat {∂J}}{∂θ})] = E_1[E_2(\frac {1}{K} \sum_{k=1}^K \frac {\widehat {∂J_k}}{∂θ})] = E_1 [\frac {1}{K} \sum_{k=1}^K E_2(\frac {\widehat {∂J_k}}{∂θ})] = E_1 [\frac {1}{K} \sum_{k=1}^K \frac {{∂J_k}}{∂θ}] = \frac {{∂J}}{∂θ}$$(3)

We summarise several advantages of the proposed framework illustrated in Fig.2. First, the modality-independent label similarity is computed between the warped moving label and the fixed label, neither of which are used as input to the network. Therefore, they are not required in the inference stage, i.e. actual registration. Second, samples of different types of labels can be fed to the training without requiring consistent number or types of anatomical structures being labelled; and potentially very large number of labels for each image pair can be used without increasing memory usage. Third, the moving and fixed images are the only inputs to the neural network without the need to define an explicit intensity-based image similarity measure that has to be tailored for different modality pairs. Matching intensity patterns will be learned by the network trained to optimise for latent label correspondence. Fourth, different regularisation terms can be added, such as bending energy (Rueckert et al., 1999), L1 - or L2 -norm of the displacement gradients (Fischer and Modersitzki, 2004; Kumar and Dass, 2009; Vishnevskiy et al., 2017), in addition to the network architectural constraints.

我们总结了如图2中所示的提出的框架的几个优点。第一，在变形的移动标签和固定标签中计算模态无关的标签相似性，这两者都没有用作网络的输入。因此，在推理阶段都是不需要的，即，实际的配准中。第二，不同类型的标签的样本可以送入训练，所标注的解剖结构的数量不需要一致；对每个图像对，都可以使用大量标签，而不需要增加内存使用。第三，移动和固定图像是神经网络的唯一输入，不需要定义显式的基于灰度的图像相似度度量，这种度量对于不同模态对是需要定制的。匹配的灰度模式可以由网络训练优化标签对应性时学习到。第四，可以加入不同的正则化项，除了网络架构约束外，比如弯曲能量，偏移梯度的L1或L2范数。

### 2.2 Multiscale Dice for Measuring Label similarity

Direct use of classical overlap metrics between binary anatomical labels, such as those based on Dice, Jaccard and cross-entropy, are not appropriate for measuring label similarity in the context of image registration. For example, they do not consider the spatial information when two foreground objects do not overlap. All of them approach extreme values, becoming invariant to the distance between the objects. Our initial work reported to use a cross-entropy with a heuristic label smoothing approach based on re-weighted inverse distance transform (Hu et al., 2018). The warped labels were approximated by interpolating pre-computed label maps, as the distance transform is neither differentiable nor efficient to compute in each iteration.

经典的二值解剖标签的重叠性度量，如那些基于Dice，Jaccard和交叉熵的，其直接使用对于在图像配准中度量标签相似性是不合适的。比如，当两个前景目标没有重叠时，并没有考虑到空间信息。它们都趋近于极值，对目标间的距离是不变的。我们初始的工作使用了带有启发式标签平滑方法的交叉熵，基于重新加权的逆距离变换。变形的标签通过对预计算的标签图进行插值进行近似，因为距离变换是不可微的，在每次迭代中也比较难于计算。

Here, we propose an alternative label similarity measure based on a multiscale Dice. The soft probabilistic Dice (Milletari et al., 2016) $δ_{Dice}$ has been shown to be less sensitive to class imbalance in medical image segmentation tasks (Sudre et al., 2017). Between two labels a={$a_i$} and b={$b_i$}, $a_i,b_i∈[0,1]$, $δ_{Dice}$ is given as follows:

这里，我们提出另一种标签相似性度量，基于一种多尺度Dice。软概率Dice $δ_{Dice}$在医学图像分割中已经证明对类别不均衡较不敏感。在两个标签a={$a_i$}和b={$b_i$}中，$a_i,b_i∈[0,1]$, $δ_{Dice}$计算如下：

$$δ_{Dice}(a,b) = \frac {2\sum_{i=1}^I a_i ⋅ b_i} {\sum_{i=1}^I a_i + \sum_{i=1}^I b_i}$$(4)

where, i=1,...,I, over I image voxels. Given the pair of binary labels $l_k^B$={$(l_k^B)_i$} and $y_k^A$={$(y_k^A)_i$} in a training minibatch. To better capture spatial information between labels, the proposed multiscale Dice is defined as:

其中i=1,...,I是在I个图像体素上的。给定训练minibatch中二值标签的对$l_k^B$={$(l_k^B)_i$}和$y_k^A$={$(y_k^A)_i$}。为更好的捕获标签之间的空间信息，提出的多尺度Dice定义为：

$$J_k = \frac {1}{Z} δ_{Dice}(f_σ(l_k^B), f_σ(y_k^A))$$(5)

where, $f_σ$ is a 3D Gaussian filter with an isotropic standard deviation σ. In this work, the number of scales Z is set to 7, with σ ∈ {0,1,2,4,8,16,32} in mm. $f_{σ=0}$ is equivalent to filtering with a Dirac delta function, meaning that an unfiltered binary label at original scale is also included when averaging $δ_{Dice}$ values. An illustration of the multiscale filtering on the anatomical labels are provided in Fig.3. The proposed Gaussian filtering based multiscale loss metric is differentiable and, if required, can be efficiently evaluated on-the-fly after non-rigid warping and necessary data augmentation.

其中，$f_σ$是一个3D高斯滤波器，各向同性标准差为σ。本文中，尺度的数量Z设为7，σ ∈ {0,1,2,4,8,16,32}单位为mm。$f_{σ=0}$等价于用Dirac delta函数进行滤波，意味着无滤波的原始尺度的二值标签也用于平均$δ_{Dice}$值。对解剖标签的多尺度滤波的描述如图3所示。提出的基于高斯滤波的多尺度损失度量是可微分的，如果需要的话，可以在非刚体变形和必要的数据扩充后，进行高效的在线计算。

For comparison, the proposed multiscale approach is also adapted with a classification loss using a negative cross-entropy: 为了进行比较，提出的多尺度方法也对于分类损失（使用的负的交叉熵）进行了调整：

$$δ_{CE}(a,b) = \sum_{i=1}^I \sum_{c=1}^2 p_c(a_i) log p_c(b_i)$$(6)

where $p_c$ represents the class probabilities between the foreground- and background classes, c={1,2}. A numerically stable implementation clipping extreme input probabilities can be used in this case.

其中$p_c$表示前景和背景类别的概率，c={1,2}。数值上稳定的实现，即剪切掉极端的输入概率，可以在这里使用。

We summarise several technical considerations in designing the proposed label similarity measure in Eq (5): 1) it has the effect of penalising high confidence binary predictions, similar to the label-smoothing regularisation approaches (Pereyra et al., 2017; Szegedy et al., 2016); 2) from a classification perspective, it further improves the gradient balance between foreground- and background classes over voxel samples in training, as a result of reducing the difference between the expected class probabilities (Lawrence et al., 2012); 3) it provides non-saturating gradients from anatomical labels, especially for those with smaller volumes, due to the high variance spatial smoothing at larger scales; 4) it is highly efficient to compute with recursive and separable convolution kernels.

我们总结一下设计提出式(5)标签相似性的几个技术考虑：1)其有惩罚高置信度的二值预测的效果，与标签平滑的正则化方法类似；2)从分类的角度来看，其进一步改进了前景和背景类别在训练过程中的体素样本的梯度平衡，这是降低期望类别概率差异的结果；3)从解剖标签中得到了非饱和的梯度，尤其对于那些有更小的体的，这是因为在更大尺度上高方差空间平滑的结果；4)用迭代的、可分离的卷积核，计算起来很高效。

### 2.3 Network Architecture

As shown in our preliminary work (Hu et al., 2018), a global sub-network predicting an affine transformation can be combined with a jointly-trained local sub-network predicting a local DDF, in order to overcome the practical difficulty in propagating the gradients from the deformation regulariser to regions with less supporting label data. In this work, we describe a new architecture utilising a single network to predict displacement summed over different resolution levels. The lower-level displacement summands provide global information, similar to that of the global sub-network but without significant memory usage by the global sub-network. These approaches are compared in Section 3.2.

如在初步工作中所展示的，一个全局的子网络，用于预测仿射变换，可以与一个联合训练的预测局部DDF的局部子网络结合到一起，以克服将梯度从形变正则化器传播到标记数据支持更少的区域中。在本文中，我们描述了一种新的架构，使用单个网络来预测偏移，在不同的分辨率层次中求和。更低层的偏移求和项提供了全局信息，这与全局子网络类似，但不需要全局子网络的太大的内存占用。这些方法在3.2节中进行了比较。

Following our previous work in segmenting prostate gland from TRUS images (Ghavami et al., 2018) and the prior art for learning optical flow (Ilg et al., 2017), the network is designed as a 3D convolutional neural network with four down-sampling blocks, followed by four up-sampling blocks. As illustrated in Fig.4, the network is more densely connected than the U-Net proposed for image segmentation (Ronneberger et al., 2015) and also has less memory requirement, featuring three types of previously proposed summation-based residual shortcuts, 1) four summation skip layers shortcutting the entire network at different resolution levels (Yu et al., 2017), 2) eight standard residual network shortcuts summing feature maps over two sequential convolution layers (He et al., 2016), and 3) four trilinear additive up-sampling layers are added over the transpose-convolution layers (Wojna et al., 2017).

按照我们之前的工作，在TRUS图像中分割前列腺，和之前在学习光流中的工作，网络设计为一个3D卷积网络，有4个下采样模块，然后有4个上采样模块。如图4所示，网络比U-Net的连接更加密集，所耗费的内存也更少，有三种之前提出的基于相加的残差连接，1)四个相加的跳跃层在四种不同的分辨率层上将网络进行了捷径连接，2)八个标准的残差网络，将两个顺序的卷积层前后的特征相加，3)四个三线性加性上采样层加入到转置卷积层中。

The benefits of deeper supervision using denser connections have been shown in computer vision tasks (He et al., 2016; Huang et al., 2016; Lee et al., 2015; Szegedy et al., 2015) and medical image analysis (Dou et al., 2017; Garcia-Peraza-Herrera et al., 2017; Gibson et al., 2017a). Besides the thoroughly applied residual shortcuts described above, we introduce summation-based skip layers to the displacement space across different resolution levels $s_{0-4}$. As sketched in the lower part of Fig.4, each side of the up-sampling blocks extends to a node to predict a trilinear-up-sampled displacement summand $δ_{1-4}$ at levels $s_{1-4}$, after an additional convolution layer added to a bias term, without batch normalisation or standard nonlinear activation. These summands, with the size of the output DDF, are then added to the summand $δ_0$ at the input image resolution level $s_0$, to predict a single output DDF.

使用更密集连接的更深监督的好处已经在计算机视觉任务和医学图像分析中得到了展示。除了上面描述的彻底应用的残差捷径连接，我们提出了基于相加的跳跃层，在四种不同分辨率层次$s_{0-4}$的偏移空间中。如在图4的下半部分所示的，上采样模块的每个边拓展到了一个节点，来预测一个三次线性上采样的偏移，在层次$s_{1-4}$上为$δ_{1-4}$，在一个额外的卷积层加上偏置项后，没有批归一化或标准非线性激活。这些加数，大小为输出的DDF，在输入图像分辨率层次$s_0$上加入到加数$δ_0$中，以预测一个输出DDF。

Physically parametrised global transformations such as rigid and affine models are sensitive to network initialisation, as in training spatial transformer networks (Jaderberg, 2015). To a lesser degree, the registration networks predicting displacements suffer the same problem. The design of these summand nodes allows random initialisation with zero mean and a small variation on the convolution weights and bias (on the displacement skip layers) with controlled magnitude of the initial DDFs, such that the warped labels generate meaningful initial gradients. The trilinear sampling provides bounded nonlinear activation between linear convolutions.

参数的全局变换，如刚性和仿射模型，对于网络的初始化是敏感的，就像在训练STN网络中一样。配准网络预测的偏移也存在同样的问题，只不过更轻一些。这些加数节点的设计，可以用零均值小方差，对卷积权重和偏置进行随机初始化（在偏移跳跃层中），初始DDF的幅度是受控的，这样变形的标签会生成有意义的初始梯度。三线性采样在线性卷积之间提供了有边界的非线性激活。

The described additive displacement skip layers are more efficient to compute and, potentially, easier to train, comparing to composing displacements at different levels or concatenating warped input images (Ilg et al., 2017; Yu et al., 2016), both requiring resampling. It is noteworthy that the described four displacement skip layers are determined by the network up-sampling levels, therefore are independent to the choice of scales in the label similarity measure above-described in Section 2.2, which evaluates the loss with respect to the single output DDF.

描述的加性偏移跳跃层，与将不同的层次中的偏移结合起来，或拼接变形的输入图像相比较，这两者都需要重采样，计算起来更高效，而且训练起来也可能更容易。值得注意的是，描述的四个偏移跳跃层，是由网络上采样层决定的，因此与标签相似度度量中的尺度的选项是不相关的，后者评估的是相对于单个输出DDF的损失。

As illustrated in Fig.4, the first feature maps begin with n0 initial channels, successively doubles the number of channels and halves the feature map size with the down-sampling blocks, and vice versa with the up-sampling blocks. Each of these blocks consists of two convolution- and batch normalisation (BN) layers with rectified linear units (relu). 3D down- and up-sampling are achieved respectively by max-pooling (maxpool) and transpose-convolution (deconv) layers, both with strides of two. All convolution layers have 3*3*3 kernels, except for 7*7*7 kernels used in the first convolution layer to ensure sufficient receptive field.

如图4所示，第一个特征图有n0个初始通道，然后通道数量加倍，特征图大小通过下采样模块减半，上采样模块也是一样的。每个模块包含两个卷积层，和BN层，和ReLU单元。3D下采样和上采样分别通过max-pooling和转置卷积层进行实现，步长都是2。所有的卷积层的核大小都是3*3*3，除了7*7*7的核用在第一个卷积层中，可以确保足够的感受野大小。

## 3 Experiments

### 3.1 Data

A total of 108 pairs of T2-weighted MR and TRUS images from 76 patients were acquired during SmartTarget® clinical trials (Donaldson et al., 2017). Each patient had up to three image data sets due to the multiple procedures he entered, i.e. biopsy and therapy, or multiple ultrasound volumes acquired at the beginning and the conclusion of a procedure according to the therapy trial protocol (“SmartTarget: BIOPSY,” 2015, “SmartTarget THERAPY,” 2014). Using a standard clinical ultrasound machine (HI-VISION Preirus, Hitachi Medical Systems Europe) equipped with a bi-plane (C41L47RP) transperineal probe, a range of 57 - 112 TRUS frames were acquired in each case by rotating a digital transperineal stepper (D&K Technologies GmbH, Barum, Germany) with recorded relative angles covering the majority of the prostate gland. These parasagittal slices were then used to reconstruct a 3D volume in Cartesian coordinates (Hu et al., 2017). Both MR and TRUS images were normalised to zero-mean with unit-variance intensities after being resampled to 0.8×0.8×0.8 mm3 isotropic voxels.

在SmartTarget®临床试验中，获取了76位患者的共计108对T2加权的MR和TRUS图像。每位患者进行了多次手术，所有最多有三个图像数据集，即，活检和治疗，或根据治疗试验协议，在手术的开始和结论时获得的多个超声体。使用一个标准的临床超声机器，装备一个双平面经会阴探头，在每个病例中，通过旋转一个数字经会阴stepper（相对角度会有记录）覆盖了前列腺的主要部分，获取了57-112帧TRUS图像。这些parasagittal切片然后用于在笛卡尔坐标系中重建3D体。MR和TRUS图像都重采样到0.8×0.8×0.8 mm3的各向同性体素大小，然后归一化到零均值单位方差灰度。

From these patients, a total of 834 pairs of corresponding anatomical landmarks were labelled by two medical imaging research fellows and a research student using an in-house voxel-painting tool on the original image data, and all were verified by second observers including a consultant radiologist and a senior research fellow. Prostate gland segmentations on MR images were acquired as part of the trial protocols (Donaldson et al., 2017). The gland segmentations on TRUS images were manually edited based on automatically contoured prostate glands on original TRUS slices (Ghavami et al., 2018). Besides full gland segmentations for all cases, the landmarks include apex, base, urethra, visible lesions, junctions between the gland, gland zonal separations, vas deference and the seminal vesicles, and other patient-specific point landmarks such as calcifications and fluid-filled cysts (see also Fig.1 and Fig.3 for examples). The label pairs used in this study include 108 (12.9%) pairs of gland segmentations, 213 (25.5%) apex or base pairs, 214 (25.7%) corresponding structures on zonal boundaries, 37 (4.4%) on urethra and 262 (31.4%) patient-specific regions of interest such as calcification sediments and cysts, with an average volume of 0.39±0.21 cm3 and a range of [0.13, 18.0] cm3 excluding the gland segmentations. The landmark annotation process took more than 200 hours. The anatomical labels, represented by binary masks, were resampled to the sizes and resolutions of the associated MR or TRUS images, and were re-grouped for training (described in Section 2.1) and for validation in a cross-validation scheme described in Section 3.3.

从这些患者中，由两位医学影像研究员和一位研究学生，使用室内的体素绘制工具，在原始图像数据中，标注了834对对应的解剖特征点，所有这些标注都有其他人进行验证，包括一个咨询放射学家，和一个资深研究员。作为部分试验协议，可以获得MR图像的前列腺分割。在TRUS图像上的腺体分割，是基于在原始TRUS切片上的自动勾画的前列腺进行的手动修改。除了所有病例的完整腺体分割，特征点包括apex, base, urethra, 可见的损伤，腺体之间的接合处，腺体的带状分隔，输精管和精囊，以及其他的患者特定的特征点，如钙化部位和充满液体的囊（见图1和图3的例子）。用在这个研究中的标签对，包含108对腺体分割（12.9%），213对apex或base（22.5%），214对在带状边缘的对应结构（25.7%），37对在尿道上（4.4%），262对患者特定的感兴趣区域（31.4%），如钙化沉积物和囊，平均体积0.39±0.21 cm3，范围为[0.13, 18.0] cm3，排除了腺体分割。特征点标注过程花费了超过200小时。解剖标记，由二值掩膜表示，重采样到相关的MR或TRUS图像的大小和分辨率，并重新分组进行训练（如2.1节所述），以及验证，交叉验证方案如3.3节所述。

### 3.2 Implementation and Network Training

The described methods were implemented in TensorFlowTM (Abadi et al., 2016) with a trilinear resampler module and a 3D image augmentation layer adapted from open-source code in NiftyNet (Gibson et al., 2017b). Re-implementation of all the networks reported in the experiment are available as part of NiftyNet (niftynet.io). Each image-label pair was transformed by a random affine transformation without flipping before each training iteration for data augmentation. Each network was trained with a 12GB NVIDIA® PascalTM TITAN Xp general-purpose graphic process unit (GPU) for 48 hours on a high-performance computing cluster.

方法是用TensorFlow实现的，三线性重采样模块和3D图像扩增层是从NiftyNet的开源代码中改编过来的。试验中所有网络的重实现是NiftyNet的一部分。每个图像标签对都在每个训练迭代之前，用随机仿射变换进行改变，不进行翻转，用于数据扩增。每个网络都用12GB NVIDIA® PascalTM TITAN Xp在一个高性能计算集群中进行训练48小时。

#### 3.2.1 The Proposed Baseline Network and Variants

Without extensively searching and refining the hyper-parameters, which could systematically underestimate the reported generalisation error, an empirically configured “Baseline” network was trained using the Adam optimiser starting at a learning rate of 10^-5, with a minibatch of 4, four full-sized image-label quartets. The deformation regularisation weight was set to α = 0.5, between the bending energy and the multiscale Dice, described in Section 2. The weight decay was not used. Initial number of channels for feature maps was set to n0=32. All network parameters were assigned initial values using Xavier initialiser (Glorot and Bengio, 2010), except for the final displacement prediction layers to allow controlled initial outputs as discussed in Section 2.3. These convolutional kernel and bias parameters were initialised to zeros for the results reported in this paper. We refer to the network trained with these hyper-parameters as the “Baseline” network, for comparing with the networks using different hyper-parameters. Except for each of the hyper-parameter of comparison, these configurations were kept fixed in the following networks.

我们并没有广泛的搜索并优化超参数，这可能会低估得到的泛化误差，我们只是从经验上配置了基准网络，使用Adam优化器进行了训练，学习速率从10^-5开始，mini-batch大小4，四个完整大小的图像标签quartets。形变正则化权重设置为α = 0.5，在bending能量和多尺度Dice之间，如第2部分所述。权重衰减并没有使用。特征图的初始的通道数量设为n0=32。所有网络参数都用Xavier初始化来指定初始值，除了最终的偏移预测层。本文中这些卷积核和偏置参数初始化为0。我们称使用这些超参数训练的网络为基准网络，以与使用不同的超参数的网络进行比较。除了每个超参数的比较，这些配置在下面的网络中保持固定。

Two variants of the proposed “Baseline” network loss function are compared, training with 1) a multiscale cross-entropy, described in Section 2.2 (“Baseline-msCE”), instead of the multiscale Dice, or 2) replacing the bending energy with an average L2 -norm of the displacement gradients (“Baseline-L2”).

提出的基准网络损失函数的两个变体进行了比较，使用1)多尺度交叉熵，2.2节中所述(“Baseline-msCE”)，而不是使用多尺度Dice，或2)将bending energy替换为偏移梯度的L2范数(“Baseline-L2”)。

Although one of the advantages of the proposed label similarity measure in Eq. (5) is computational efficiency when required on-the-fly, pre-computing Gaussian filtered labels before training, may further accelerate training. Therefore, a baseline network using label maps pre-filtered at different scales (“Baseline-preFilt”) was trained, while the Dice metrics were evaluated directly on the resampled multiscale label maps during training.

虽然提出的标签相似性度量式(5)的一个优势是计算效率高，在训练之前预计算高斯滤波的标签，可能会进一步加速训练。因此，训练了使用标签图在不同尺度上的预滤波基准网络(“Baseline-preFilt”)，而Dice度量在重采样的多尺度标签图上直接进行了计算。

To validate the proposed network architecture, the “Baseline” network was trained with only the displacement δ0 predicted at the input image resolution level s0, i.e. without displacement summands δ1-4 at resolution levels s1-4 (“Baseline-δ0”, illustrated in Fig.5b). This is similar to the “Local-Net” proposed in our preliminary work (Hu et al., 2018). Furthermore, previous work suggested that, regularised displacements predicted at finest level may not be necessary (Dosovitskiy et al., 2015). Therefore, the “Baseline” network was also trained with all the displacement summands except for the one at level s0, that is a network with displacement summed over the outputs at levels s1-4 (“Baseline-δ1-4”, illustrated in Fig.5c). For both networks, the down- and up-sampling blocks remain the same.

为核实提出的网络架构，基准网络的训练只使用了δ0偏移，在输入图像分辨率层次s0进行预测的，即，不需要在分辨率层次s1-4的偏移加数δ1-4（“Baseline-δ0”，如图5b所示）。这与我们初步工作中提出的Local-Net类似。而且，之前的工作说明，在最精细的层次预测的正则化的偏移，可能不一定是够的。因此，基准网络也是使用所有偏移加数进行训练的，除了在层次s0的那个，那是一个使用在层次s1-4上的输出相加的偏移的网络(“Baseline-δ1-4”, 如图5c)。对于两个网络，下采样和上采样模块保持一致。

#### 3.2.2 Comparison with the Previous Networks of (Hu et al., 2018)

A “Global-Net”, illustrated in Fig.6, was proposed to predict an affine transformation using the same learning framework described in Section 2.1. A “Composite-Net” was proposed to compose the output DDFs from the “Global-Net” and the “Local-Net”, as illustrated in Fig.7. The details of the compared “Global-Net” and the “Composite-Net”, are described in (Hu et al., 2018). A direct comparison to the previously reported numerical results may be unfair due to the difference in data sets and the associated training strategy. For example, the results reported in this paper are based on substantially more anatomical labels verified by second observers (described in Section 3.1) without the less-frequently-sampled “low-confidence” labels (Hu et al., 2018). In the interest of a direct comparison between different network architectures, the “Global-Net” and the “Composite-Net” were re-trained using the same multiscale Dice as the “Baseline” networks, with a smaller starting learning rate of 10^-6 to avoid otherwise frequently encountered divergence (due to the sensitivity of the output displacements to the affine parameters). A 24GB NVIDIA® QuadroTM P6000 GPU card was used to train the “Composite-Net” that needs more than 12GB GPU memory for the same minibatch size.

图6中的Global-Net，用于预测一个仿射变换，使用的是2.1节中描述的相同的学习框架。一个Composite-Net提出用Global-Net和Local-Net的结果组成输出的DDF，如图7所示。比较的Global-Net和Composite-Net的细节，在(Hu et al., 2018)中有表述。之前给出的数值结果的直接比较可能是不公平的，因为有数据集和相关的训练策略的差异。比如，本文中给出的结果，更多的是基于解剖标签的（由其他人核验过），而没有没那么频繁的采样的低置信度标签。我们要对不同的网络架构进行直接比较，Global-Net和Composite-Net与基准网络一样使用了同样的多尺度Dice进行了重新训练，初始学习速率更小10^-6，以防止其他频繁遇到的发散（由于输出偏移对仿射参数的敏感性）。我们用一个24GB NVIDIA® QuadroTM P6000 GPU来训练Composite-Net，对于同样的mini-batch大小，需要超过12GB GPU内存。

### 3.3 Cross-Validation

All the numerical results reported in this paper were based on a 12-fold patient-level cross-validation for each network. In each fold, test data from 6-7 patients were held out while the data from the remaining patients were used in training. Two measures are reported in this study: centroid distance error between centres of mass is computed from each pair of the warped and fixed labels; the target registration error (TRE) is defined as root-mean-square on these distance errors over all landmark pairs for each patient. A Dice similarity coefficient (DSC) is the overlap between the binary warped and fixed labels representing prostate glands. These two independently-calculated metrics on left-out test data directly relate to the clinical requirements in the registration-enabled guidance, avoiding surrounding healthy or vulnerable structures and locating regions of interest. Paired Wilcoxon signed-rank tests at significance level αH=0.05 were used to compare medians of the cross-validation results between the networks. Confidence intervals (CIs) were also reported in cases where the obtained p-values are larger than αH. The cross-validation scheme ensures all the anatomical landmarks (details described in Section 3.1) are independently tested in different folds without being used in training.

本文中给出的所有的数值结果，是基于对每个网络的12-fold 患者级的交叉验证。在每个fold中，保留6-7个患者的测试数据，其他的数据则用于训练。这个研究中给出两个指标：对每一对变形的和固定的标签，计算其物质中心的中心点距离误差；TRE定义为每个患者的所有的特征对的这些距离误差的均方根。DSC是表示前列腺的变形的二值标签和固定标签的重叠。在保留的测试数据上，这两个独立计算的度量，与配准导航的临床要求直接相关，避免周围的健康或脆弱结构，并定位感兴趣区域。显著性程度αH=0.05的成对Wilcoxon signed-rank用于比较网络之间交叉验证结果的中值。置信区间(CIs)在得到的p值大于αH时也给出了。交叉验证方案确保了所有的解剖特征点在不同的fold上进行了独立的测试，而没有用于训练。

### 3.4 Comparison with Pairwise Image Registration Methods

As discussed in Section 1, generic pairwise registration algorithms were generally found to perform poorly in registering MR and TRUS images for this application, which has in turn motivated many application-specific methods, such as prostate motion modelling and intraoperative rigid initialisation, e.g. (De Silva et al., 2017). To confirm this observation on the same data set in this work, a set of non-linear registrations were tested using a GPU-enabled open-source algorithm (Modat et al., 2010). The B-splines free-form deformation regularised by bending energy (Rueckert et al., 1999), weighting being set to 0.5 for comparison, was optimised with respect to three intensity-based similarity measures, normalised mutual information (NMI), normalised cross-correlation (NCC) and sum-of-square differences (SSD). In addition to directly applying the registration without any initial alignment, two simple global initialisation methods, an automatic rigid registration minimising the same similarity measures and a manual initialisation matching the gland centroids, were also tested. A total of 972 registrations were run on GPU using the data set described in Section 3.1. The TREs and DSCs were computed with all the other default configurations kept as the same for comparison. These results aim to demonstrate typical performances using pairwise intensity-based registration algorithms for this multimodal MR-to-TRUS prostate imaging application. Methods with substantial customised adaptations (discussed in Section 1), such as spatial initialisation (manual or automated) or statistical motion modelling, were also compared quantitatively based on published results and are summarised in Section 4.4.

如在第一部分所讨论的，一般的成对配准算法在配准MR和TRUS图像中效果不好，所以促进了很多特定应用的方法，如前列腺运动建模和术中刚体初始化。为在本文中在同样的数据集上核实这种观察，我们使用的一种使用GPU的开源算法测试了一系列非线性配准。B样条自由形式形变，带有bending energy的正则化，加权设置为0.5，以进行比较，对于三个基于灰度的相似性度量进行优化，归一化的互信息(NMI)，归一化的互相关(NCC)和距离平方和(SSD)。除了直接应用配准而不进行任何初始对齐，还测试了两种简单的全局初始化方法，一种自动刚体配准，最小化相同的相似性度量，和一种手动初始化，匹配的是腺体中心。在GPU上使用3.1节描述的数据集进行了共计972个配准。计算了TREs和DSCs，其他默认配置保持一样以进行比较。这些结果的目标是，使用成对的基于灰度的配准算法，对这个多模态MR-TRUS前列腺成像应用，证明典型的性能。使用定制的改变的方法（在第一部分进行了讨论），比如空间初始化（手动的或自动的），或统计运动建模，也基于发表的结果进行了定量的比较，这在4.4节进行了总结。

## 4 Results

### 4.1 “Baseline” Performance

Approximately four 3D registrations per second can be performed on the same GPUs. The “Baseline” network achieved a median TRE of 3.6 mm on landmark centroids with first and third quartiles being 2.3 and 6.5 mm, respectively. A median DSC of 0.87 on prostate glands was obtained from the same networks with first- and third quartiles being 0.82 and 0.89. More detailed results are summarised in Table 1 and illustrated in Fig.8. Example slices from the input MR and TRUS image pairs and the registered MR images are provided in Fig.9 for qualitative visual assessment of the registration results based on the test data.

在同样的GPUs上，每秒可以进行大约4个3D配准。基准网络在特征点重心上得到的TRE的中值为3.6mm，前1/4和第3个1/4分别为2.3mm和6.5mm。同样的网络在前列腺上的DSC中值为0.87，第1和第3个1/4分别为0.82和0.89。更详细的结果如表1和图8所示。输入MR和TRUS图像对的例子slices，和配准的MR图像，如图9所示。

### 4.2 Variants of the “Baseline” Network

Considering the “Baseline” network was trained with respect to the loss function based on multiscale Dice, it is interesting that replacing the multi-scale Dice with cross-entropy (i.e. using “Baseline-msCE” network) had a significantly worse TRE (p-value<0.001), but a better binary (single-scale) DSC result (p-value=0.046). This may suggest that the superior class balance was conveyed by the multiscale Dice as discussed in Section 2.2. Thus, the bias towards labels having larger volumes, such as the prostate glands producing the DSC results, is lessened. The “Baseline-L2” using a different deformation regularisation produced poorer generalisation ability, both in terms of TRE (p-value=0.049) and DSC (with both p-values<0.001), although it is intended to demonstrate the suitability to use different forms of regularisation without excessively tuning each hyper-parameter in this experiment.

考虑基准网络是用基于多尺度Dice的损失函数进行训练的，将多尺度Dice损失替换为交叉熵（即，使用Baseline-msCE网络），其TRE显著恶化(p-value<0.001)，但二值DSC结果更好(p-value=0.046)，这非常有趣。这可能说明，很好的类别均衡可以更好的由多尺度Dice传递出来。因此，偏置更倾向于有更大体积的标签，比如前列腺得到的DSC结果减少了。使用一种不同的形变正则化的Baseline-L2得到了更差的泛化能力，TRE(p-value=0.049)和DSC (p-values<0.001)都是，虽然本意是证明使用不同形式的正则化的合适性，而在这个试验中不需要过度的调节每个超参数。

It may be of practical importance to report that pre-computing the label filtering did not have a negative impact on TRE (p-value=0.458, CI=[-1.433, 0.634]) or on DSC (p-value=0.498, CI=[-0.009, 0.030]). However, the “Baseline-preFilt” is faster to train. Depending on the implementation of the online filtering and the parsing of the additional pre-computed labels, an approximately 25% gain in training time was achieved in our experiments using pre-computed labels.

预先计算标签滤波，对TRE并没有很差的影响(p-value=0.458, CI=[-1.433, 0.634])，或DSC (p-value=0.498, CI=[-0.009, 0.030])。但是，Baseline-preFilt训练起来更快。依赖于在线滤波的实现和额外的预先计算的标签的解析，在我们的试验中，使用预计算的标签，训练时间大约可以提速25%。

The “Baseline” network outperformed the “Baseline-δ0” network predicting the local displacement only at the finest input image resolution level, with p-value=0.034 and p-value=0.003, for comparing TREs and DSCs, respectively. This improvement was consistently achieved during the experiments with different network hyper-parameters. On the other hand, the “Baseline-δ1-4” without predicting displacement at finest resolution level performed competitively, consistent with the conclusions from the previous work (Dosovitskiy et al., 2015) that prediction at the original resolution level does not necessarily improve the accuracy. It produced TREs and DSCs with no statistically significant difference than those from the “Baseline”, p-value=0.477 (CI=[-1.342, 0.735]) and p-value=0.316 (with a CI of [-0.011, 0.023]), respectively. Furthermore, using the “Baseline” network without the trilinear additive up-sampling layers, described in Section 2.3, resulted in a significantly higher median TRE of 6.4 mm (p-value<0.001).

基准网络在预测局部偏移上超过了Baseline-δ0网络，但这只在最精细的输入图像分辨率层级，对于TREs和DSCs的比较，分别有p-value=0.034和p-value=0.003。这种改进在试验中采用不同的网络超参数，都可以获得。另外，Baseline-δ1-4的表现也非常好，在最精细的分辨率层次并没有预测偏移，与之前的工作中的结论一致，即在原始分辨率层级的预测对于改进准确率并没有必要。其产生的TREs和DSCs，与基准网络中的在统计意义上并没有明显差异，分别是p-value=0.477 (CI=[-1.342, 0.735])和p-value=0.316 (CI=[-0.011, 0.023])。而且，使用基准网络，不带有三线性加性上采样层，如2.3节描述，得到明显更高的TRE 6.4mm (p-value<0.001)。

### 4.3 Comparison Results with the Previous Networks of (Hu et al., 2018)

The TREs and DSCs from the “Baseline” network are significantly better than those from “Global-Net” which only models the affine transformation (both p-values<0.001). This clearly demonstrates the efficacy of the deformable registration in this application. Comparing to the previously proposed “Composite-Net” architecture, not only the GPU memory to train the “Global-Net” can be spared, but also improvement in generalisation was observed from the proposed network, in terms of both TRE and DSC (both p-values<0.001).

基准网络的TREs和DSCs明显优于Global-Net，后者只对仿射变换进行建模（两者的p-values<0.001）。这很清楚的证明了在这个应用中形变配准的效率。与之前提出的Composite-Net架构相比，不仅可以省去训练Global-Net的GPU内存，而且提出的网络还有泛化性能上的改进，TRE和DSC上都有。

Because a relatively large weight α = 0.5 in Eq. (2) was used in this multimodal application, negative Jacobian determinants were not found in any of the DDFs predicted by the trained networks. For further inspection of the deformation fields, we plotted the determinants of the Jacobian, the magnitudes of the displacement vectors and the L2-norms of the displacement gradients, as illustrated in the rows of Fig.10, J, D and G, respectively. For example, the “Baseline” (left columns), “Baseline-δ0” (middle columns) and an illustrative network trained with small regularisation weight α = 0.01(right columns) produced DDFs with visibly increasing variance. Both standard deviations and numerical ranges of these three quantities increase in the same order consistently. Negative Jacobian determinants also appeared as the regularisation weight decreases to α = 0.01, implying that physically implausible deformation may exist in the illustrative example without appropriate regularisation.

因为式(2)中相对较大的权重α = 0.5用于这个多模态应用，训练的网络预测的DDFs中并没有发现负的Jacobian行列式。为进一步检查形变场，我们画出了Jacobian行列式，偏移向量的幅度和偏移梯度的L2-范数，分别如图10的J，D和G所示。比如，基准（左列），Baseline-δ0（中列）和用小的正则化权重α = 0.01训练的描述性网络（右列）生成的DDFs其方差是逐渐增加的。标准差和这三个量的数值范围以同样的顺序一致增加。负的Jacobian行列式在正则化权重降低到α = 0.01时也出现了，说明如果没有合适的正则化的话，物理上不可能的形变也可能在样本中存在。

### 4.4 Comparison with Pairwise Registration Methods

For the comparison with the pairwise registrations described in Section 3.4, we report that all 9 median TREs are larger than 24 mm and none of the DSC medians are higher than 0.77. Direct application of the intensity-based registration result in median TREs ranging 26.7-35.0 mm, with and without the rigid initialisation, for all three similarity measures. Manually aligning the prostate gland centroids immediately led to a median TRE of 19.6 mm with a median DSC of 0.79, without further registration. With the manual centroid-alignment as initialisation, registrations using NMI, NCC and SSD produced higher median TREs of 20.6, 24.7 and 25.6 mm, with lower median DSCs of 0.77, 0.67 and 0.65, respectively. The results are also summarised and compared with other previously proposed methods in Table 2, with an initial median TRE of 34.8 mm before registration. These inferior performances appear much worse than the results summarised in Table 1 and those from previous application-specific methods, e.g. (De Silva et al., 2017; Hu et al., 2012; Khallaghi et al., 2015; Sun et al., 2015; van de Ven et al., 2015; Wang et al., 2016a). It should clearly indicate the nontrivial difficulties for these general-purpose intensity-based algorithms in this multimodal registration application.

与成对配准的比较，如3.4节所述，我们给出的结果是，所有9个TREs中值都大于24mm，没有DSC的中值大于0.77。直接将基于灰度的配准应用的结果是，TREs中值范围是26.7-35.0mm，包括带有刚性初始化，不带刚性初始化，所有三种相似度度量的。手动对齐前列腺重心，可以得到中值TRE为19.6mm，中值DSC 0.79，没有进一步的配准。用手动重心对齐作为初始化，使用NMI，NCC和SSD配准得到了更高的TREs，20.6, 24.7和25.6 mm，中值DSCs更低，0.77, 0.67和0.65。结果也进行了总结，与之前提出的方法在表2中进行了比较，配准之前的初始TRE中值为34.8mm。这比表1中的结果要差很多，还有之前的应用专用的方法。这明确说明，这些通用目标的基于灰度的算法在这种多模态配准应用中有很大的难度。

For the same application, the previous studies validated on patient data reported an expected-TRE range of 1.4-2.8 mm, (De Silva et al., 2017; Hu et al., 2012; Khallaghi et al., 2015; van de Ven et al., 2015; Wang et al., 2016a). These results were based on smaller sample sizes (ranging from 8 to 29 cases) with significant variations, for example, an individual-TRE range of 0.8-8.0 mm (van de Ven et al., 2015) was reported. Although intensity-based registration has also been adopted for this application, they usually rely on customised optimisation and/or manual initialisation. For instance, a previous study (Sun et al., 2015) reported a median TRE of 1.8 mm on 20 patients, using a dual optimisation with modality independent neighbourhood descriptor after an initialisation method based on six manual landmarks from expert observers for each registration. Our method is fully automated without requiring any initialisation, pre- or intra-procedural segmentation, once the registration network is trained. One of the latest developments also reported an automated initialisation based on predicting rigid prostate motion (De Silva et al., 2017), but all the other approaches still require either manual (partial) segmentation of the TRUS images or manual initialisation in order to obtain robust registrations. None of these methods reported a faster registration execution time than the sub-second performance with the proposed registration network.

对于同样的应用，之前在患者数据上验证过的研究，给出的期望TRE范围为1.4-2.8mm。这些结果是基于更小的样本大小的（从8到29例），并有显著的变化，比如，有文献给出了单个的TRE范围为0.8-8.0mm。虽然基于灰度的配准也在这种应用中采用了，但他们通常依赖于定制的优化或手动的初始化。比如，之前的研究在20例患者上给出了1.8mm的TRE中值。我们的方法是完全自动的，一旦网络训练好之后，不需要任何初始化，术前分割，或术中分割。一种最新的进展也是自动初始化的，基于预测刚性前列腺运动的，但所有其他方法仍然需要手动分割TRUS图像，或手工初始化以得到更稳健的配准。这些方法与我们提出的配准网络比，都没有更快的配准时间，达到小于1s的性能。

## 5 Discussion

In this work, we demonstrated the feasibility of non-iterative prediction of voxel correspondence from unlabelled input images, using training image pairs with only sparse annotations. The proposed method targets a wide range of clinical applications, where automatic multimodal image registration has been traditionally challenging due to the lack of reliable image similarity measures or automatic landmark extraction methods.

本文中，我们证明了从未标注的输入图像中非迭代预测体素对应性的可行性，使用的训练图像对只有稀疏的标注。提出的方法可用于很广泛的临床应用，其中自动多模图像配准一直都很有挑战性，由于缺少可靠的图像相似度度量或自动特征点提取方法。

The use of sparse training and validation labels to predict and evaluate dense correspondence raises interesting open questions. The sparse training landmark pairs cannot independently represent voxel-level dense correspondence for an individual case. This is commonly addressed by application-independent deformation smoothness penalty in pairwise methods. Our architecture enables the regularised DDF to be implicitly learned from samples of latent dense correspondences, with the presented results suggesting that the population-trained application-specific regularisation improves the registration accuracy on unseen landmarks. For validation of dense correspondence, in the absence of ground-truth correspondence maps for real patient data, using sparse landmarks has become standard practice, interpreting independent landmark misalignments as samples of the dense registration error, e.g. (De Silva et al., 2017; Hu et al., 2012; Khallaghi et al., 2015; van de Ven et al., 2015; Wang et al., 2016a). All these studies adopted the same validation strategy based on available anatomical landmarks within or around prostate glands (described in Section 3.1), which have been shown to represent a spatial distribution relevant to the clinical localisation and targeting applications. Although MR and TRUS prostate images have limited number of salient corresponding features (approximately eight landmark pairs per image were annotated in this work), pooling these samples across 108 cases has enabled us to measure sub-millimetre accuracy differences with statistical significance. In practice, reliably finding substantially more paired corresponding anatomies has been proven challenging for experienced clinicians and researchers. Therefore, it is our opinion that further improvement in registration performance in terms of more accurate prediction of voxel correspondence may resort to increasing number of image/subject pairs or better regularisation strategy containing prior knowledge of the application-specific deformation, rather than increasing the number of landmarks per image pair.

使用稀疏的训练和验证标注，来预测和评估密集对应性，提出了有趣的开放问题。稀疏的训练特征点对，对于单个情况来说，不能独立的代表体素级密集对应性。在成对的方法中，这通常是由与应用无关的形变平滑性惩罚项处理的。我们的架构可以从潜在的密集对应性中，隐式的学习到正则化的DDF，给出的结果也说明，改进了在未曾见过的特征点上的配准准确率。为了验证密集对应性，在对真实患者数据缺少真值对应性图的情况下，使用稀疏的特征点成为了标准操作，将独立的特征点错对齐，解释为样本的密集配准误差。所有这些研究采用了相同的验证策略，基于可用的解剖特征点，在前列腺内部或附近，代表了临床定位相关的空间分布。虽然MR和TRUS图像的显著对应特征较少（本文中每对图像标注了大约8个特征点对），在108例中用这些样本使我们可以得到亚毫米的准确性。在实践中，可靠的找到更多成对的对应的解剖结构，对于有经验的医生和研究者来说，是非常有挑战的。因此，我们的意见是，进一步改进配准性能，预测更准确的体素对应性，可以诉诸于增加图像/对象对，或更好的正则化策略，包含特定应用的变形的先验知识，而不是增加每个图像对中的特征点数量。

In this work, we propose the multiscale Dice in Eq. (5) because of its ability to balance the inter-class gradient difference, discussed in Section 2.2, although the cross-entropy loss has an arguably more interpretable probability formulation for the weak voxel-level correspondence (Hu et al., 2018). Methods with weighting strategies such as generalised Dice (Sudre et al., 2017) and weighted cross-entropy (Ronneberger et al., 2015) did not seem to further improve the results in our application, probably due to the highly constrained outputs in the registration task. It is also interesting that some training labels overlap with each other, such as the gland segmentations and those defined within the prostate glands. Further quantitative analysis may be interesting to reveal the effect of these overlaps on registration performance. We envisage that, instead of heuristic weight-balancing to improve performance metrics, future investigation shall focus on risk analysis (Elkan, 2001) for specific applications to quantitatively optimise the utilities of the registration, such as those associated with clinical risks.

本文中，我们在式(5)中提出了多尺度Dice，因为其能够平衡类别间的梯度差异，这在2.2节进行了讨论。采用加权策略的方法，比如通用Dice和加权的交叉熵，在我们的应用中不会进一步改进结果，很可能是由于在配准任务中高度约束的输出。一些训练标签是相互重叠的，这也很有趣，比如腺体的分割和那些在前列腺中定义的。进一步的定量分析，会看到很有趣的在配准性能的重叠。我们设想了，不用直观的加权平衡来改进性能度量，进一步的调查应当会关注在风险分析中，以定量的优化配准的功用，比如那些与临床风险相关的。

The DDFs, also discussed in Section 4.3, were predicted without explicitly enforced topology preservation, due to the relatively heavy regularisation required in this application. However, in applications where larger numbers of landmarks can be identified feasibly and larger deformations are clinically plausible, the network may be adapted, e.g. to penalise Jacobian-based regulariser, in seeking highly accurate registration. Furthermore, the final displacement field in our proposed network could also be represented by a composition of outputs δ0-4, instead of the proposed summation. It is computationally more expensive and potentially more sensitive to learning rate and initialisation, but may predict meaningful DDF components at different resolution levels, for instance, for allowing multi-level sparsity regularisation (Schnabel et al., 2001; Shi et al., 2012).

DDF也在4.3节中进行了讨论，在预测的时候，没有显式的加入拓扑保持的约束，因为这个应用中需要较多的正则化。但是，在可以检测到更多的特征点的应用中，而且更大的形变也是临床可行的应用中，网络可能需要修改，如，来惩罚基于Jacobian的正则化器，以寻找高度准确的配准。而且，在我们的提出的网络中的最终的偏移场，可以表示为输出δ0-4的组合，而不是提出的相加。计算量会更加大，可能对学习速率和初始化更加敏感，但可能会在不同分辨率层次熵预测到有意义的DDF，比如，可以进行多层次的稀疏性正则化。

Whilst the reported cross-validation results were based on independent landmarks unseen in training, we would like to note that a limitation in the validation is that a sizable data set completely unseen to the methodology development was not available to test the generalisation ability conclusively. This is why we resort to cross-validation and did not pursue exhaustive hyper-parameter tuning. For example, the weight of bending energy was fixed among the baseline networks but was only set empirically after a limited number of trial runs on partial data set. Unbiased model searching methods for small- to medium sized training data remain an interesting future research direction.

给出的交叉检验结果是基于独立的特征点的，在训练中未曾见过，我们应当说明，验证的一个局限是，要用之前从未见过的数据集，以测试泛化能力，这不太可行。这就是我们为什么诉诸于交叉验证，而没有追求穷举式的超参数调节。比如，bending energy的权重在基准网络中是固定的，但只是根据有限次试验后通过经验设置的。对于小型或中型的训练数据，无偏的模型搜索方法，仍然是一个有趣的未来研究方向。

In summary, we have introduced a registration framework that is flexible enough to utilise different neural network architectures, deformation regularisers, and anatomical features with varied sizes, shapes and availabilities, and to match input image intensity patterns. The trained network enables a fast and fully-automatic multimodal image registration algorithm using only input image pair. Registration results are reported from a validation on 108 labelled intraoperative prostate image pairs. Future research aims to investigate the generalisation of the proposed method to data from different centres and to a wider range of applications.

总结起来，我们提出了一种配准框架，非常灵活，可以利用不同的神经网络架构，形变正则化器，和解剖结构特征，大小、形状和可用性都可以不固定，也可以匹配输入图图像灰度模式。训练好的网络可以进行快速的全自动的多模态图像配准，只使用输入的图像对。配准结果在108个标注的术中前列腺图像对中进行了验证。未来的研究目标为，研究提出的方法的泛化性，应用到不同的应用中。